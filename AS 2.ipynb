{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from the Keras Example https://keras.io/examples/structured_data/collaborative_filtering_movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Loading in the Dataset\n",
    "\n",
    "First we load in the small version of the dataset. As this is a **Collaborative Filtering** approach, we are interested in the **ratings.csv**, which has all over ratings made by each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/86158/Desktop/semester 3/Personalisation-22-23-main/data/ml-latest-small/ratings.csv\")  #C:\\Users\\86158\\Desktop\\semester 3\\Personalisation-22-23-main\\data\\ml-latest-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100004"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99904</th>\n",
       "      <td>671</td>\n",
       "      <td>590</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1065149296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99905</th>\n",
       "      <td>671</td>\n",
       "      <td>608</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1064890575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99906</th>\n",
       "      <td>671</td>\n",
       "      <td>745</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1065149085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99907</th>\n",
       "      <td>671</td>\n",
       "      <td>919</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1065149458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99908</th>\n",
       "      <td>671</td>\n",
       "      <td>1035</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1065149492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>671</td>\n",
       "      <td>6268</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1065579370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>671</td>\n",
       "      <td>6269</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1065149201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>671</td>\n",
       "      <td>6365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1070940363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>671</td>\n",
       "      <td>6385</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1070979663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>671</td>\n",
       "      <td>6565</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1074784724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "99904      671      590     4.0  1065149296\n",
       "99905      671      608     4.0  1064890575\n",
       "99906      671      745     4.0  1065149085\n",
       "99907      671      919     4.0  1065149458\n",
       "99908      671     1035     5.0  1065149492\n",
       "...        ...      ...     ...         ...\n",
       "99999      671     6268     2.5  1065579370\n",
       "100000     671     6269     4.0  1065149201\n",
       "100001     671     6365     4.0  1070940363\n",
       "100002     671     6385     2.5  1070979663\n",
       "100003     671     6565     3.5  1074784724\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "A list of userId and movieId pairs loaded into a Pandas DataFrame.\n",
    "\n",
    "an embedding layer as a one-hot encoding layer the size of your vocabulary, followed by a fully connected layer the size of your embedding.\n",
    "\n",
    "When we make the embedding, we will need a way of mapping back from indexes in the one-hot encoding back to the ids for the users and movies.\n",
    "\n",
    "### Vocabulary \n",
    "\n",
    "In order to make the vocabulary (all the unique ids), we can use the ``unique()`` function in ``Pandas``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = df[\"userId\"].unique().tolist()\n",
    "movie_ids = df[\"movieId\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9066"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 1029, 1061, 1129, 1172, 1263, 1287, 1293, 1339, 1343, 1371, 1405, 1953, 2105, 2150, 2193, 2294, 2455, 2968, 3671, 10, 17, 39, 47, 50, 52, 62, 110, 144, 150, 153, 161, 165, 168, 185, 186, 208, 222, 223, 225, 235, 248, 253, 261, 265, 266, 272, 273, 292, 296, 300, 314, 317, 319, 339, 349, 350, 356, 357, 364, 367, 370, 371, 372, 377, 382, 405, 410, 454, 457, 468, 474, 480, 485, 497, 500, 508, 509, 515, 527, 537, 539, 550, 551, 552, 585, 586, 587, 588, 589, 590, 592, 593, 616, 661, 720, 60, 247, 267, 318, 355, 595, 736, 778, 866, 1197, 1210, 1235, 1271, 1378, 1580, 1721, 1884, 2028, 2318, 2513, 2694, 2702, 2716, 2762, 2841, 2858, 2959, 3243, 3510, 3949, 5349, 5669, 6377, 7153, 7361, 8622, 8636, 27369, 44191, 48783, 50068, 58559, 84236, 34, 112, 141, 173, 260, 289, 329, 380, 431, 434, 435, 440, 442, 464, 541, 594, 596, 610, 858, 903, 910, 913, 919, 1011, 1016, 1022, 1028, 1030, 1031, 1032, 1033, 1036, 1073, 1079, 1089, 1097, 1125, 1127, 1136, 1194, 1196, 1198, 1200, 1206, 1208, 1213, 1214, 1219, 1220, 1222, 1225, 1230, 1240, 1243, 1257, 1258, 1259, 1265, 1270, 1278, 1282, 1285, 1288, 1291, 1298, 1307, 1332, 1334, 1344, 1356, 1372, 1374, 1376, 1377, 1380, 1387, 1388, 1396, 1544, 1663, 1674, 1805, 1858, 1917, 1918, 1954, 1961, 1967, 1968, 1994, 2000, 2002, 2003, 2005, 2014, 2018, 2020, 2021, 2033, 2034, 2046, 2054, 2064, 2078, 2080, 2081, 2085, 2086, 2087, 2091, 2094, 2096, 2100, 2102, 2109, 2110, 2114, 2115, 2124, 2140, 2141, 2143, 2144, 2161, 2174, 2194, 2248, 2263, 2268, 2289, 2348, 2371, 2403, 2406, 2409, 2454, 2467, 2551, 2616, 2628, 2640, 2659, 2683, 2699, 2723, 2734, 2770, 2788, 2791, 2795, 2797, 2804, 2822, 2867, 2872, 2877, 2902, 2903, 2916, 2918, 2986, 2987, 2991, 3016, 3034, 3039, 3040, 3060, 3071, 3101, 3104, 3108, 3169, 3208, 3210, 3251, 3255, 3263, 3265, 4006, 3, 104, 231, 277, 344, 597, 788, 1035, 1193, 1221, 1247, 1393, 1485, 1682, 1777, 1784, 1923, 1997, 2023, 2273, 2355, 2424, 2502, 2706, 2997, 3114, 3176, 3408, 3753, 3897, 3948, 4014, 4018, 4022, 4025, 4306, 4308, 4447, 4718, 4963, 4995, 5266, 5299, 5464, 5679, 5816, 5995, 6218, 6373, 6502, 6711, 6942, 8376, 8464, 8644, 30707, 30749, 30793, 33166, 33679, 34162, 35836, 40819, 41566, 41569, 48385, 111, 158, 293, 1204, 1250, 1276, 1358, 1639, 1687, 1747, 1876, 1909, 2001, 2019, 2072, 2528, 2529, 2571, 2657, 2692, 2761, 2890, 3052, 3300, 3751, 4641, 4975, 5952, 7090, 8368, 8784, 8874, 1, 21, 40, 151, 198, 207, 316, 333, 345, 534, 671, 708, 724, 737, 745, 780, 786, 924, 1080, 1148, 1223, 1231, 1242, 1275, 1302, 1353, 1373, 1375, 1394, 1408, 32, 45, 282, 520, 524, 543, 628, 805, 1500, 1552, 1617, 1625, 1704, 1754, 2139, 2302, 2324, 2329, 2353, 2423, 3147, 3578, 3916, 3996, 4011, 4019, 4034, 4226, 4262, 4448, 4886, 4896, 4973, 4993, 5064, 5378, 5445, 5630, 5650, 5989, 6378, 6870, 6874, 6879, 7143, 7438, 8533, 8873, 32587, 33493, 33794, 40583, 42007, 43556, 43871, 44004, 26, 36, 608, 733, 1059, 1177, 1357, 1411, 1541, 1584, 1680, 2125, 2249, 2278, 2291, 2391, 2396, 2427, 2490, 2501, 2539, 2857, 152, 735, 1101, 1423, 1459, 1499, 1611, 1690, 1719, 1887, 2108, 2344, 2410, 2826, 2827, 2840, 2881, 2907, 2926, 2995, 3005, 3019, 70, 126, 169, 785, 923, 1027, 1201, 2042, 2596, 3424, 6598, 26614, 48516, 51084, 58295, 71211, 77455, 79132, 80489, 80906, 81158, 81562, 88129, 91500, 91529, 91548, 96079, 96861, 97938, 104841, 106487, 529, 538, 673, 1077, 1215, 1295, 1732, 2259, 2460, 2668, 3146, 3148, 3179, 3298, 3324, 3474, 3770, 3773, 3780, 3791, 3793, 3794, 3798, 3799, 3801, 3809, 3825, 3827, 3829, 3831, 3841, 3844, 3861, 3863, 3864, 3865, 3869, 3871, 3873, 3879, 3885, 3886, 6184, 362, 531, 914, 2572, 2908, 3396, 3624, 4310, 4321, 4878, 7502, 54286, 64614, 69757, 78499, 81834, 88125, 93363, 2038, 2394, 2720, 2724, 2861, 3157, 3175, 3354, 3623, 3986, 3988, 2, 5, 6, 11, 14, 16, 19, 22, 25, 44, 82, 94, 95, 101, 107, 123, 125, 145, 149, 157, 160, 162, 163, 164, 170, 172, 175, 176, 180, 193, 196, 214, 215, 216, 230, 232, 233, 237, 246, 252, 288, 306, 307, 308, 322, 335, 342, 353, 373, 429, 441, 466, 471, 481, 483, 494, 535, 540, 549, 555, 556, 562, 574, 647, 648, 663, 665, 674, 680, 748, 750, 762, 784, 799, 800, 802, 803, 804, 832, 836, 851, 899, 904, 908, 909, 911, 912, 916, 920, 922, 926, 931, 953, 994, 1020, 1041, 1047, 1060, 1084, 1088, 1092, 1093, 1094, 1095, 1100, 1120, 1131, 1147, 1171, 1173, 1176, 1178, 1179, 1183, 1186, 1189, 1199, 1203, 1207, 1209, 1211, 1212, 1217, 1218, 1228, 1233, 1234, 1244, 1246, 1248, 1249, 1251, 1252, 1254, 1260, 1262, 1264, 1266, 1267, 1272, 1280, 1281, 1283, 1284, 1289, 1290, 1297, 1303, 1304, 1320, 1333, 1342, 1361, 1370, 1385, 1391, 1407, 1449, 1464, 1466, 1476, 1479, 1483, 1484, 1502, 1503, 1513, 1517, 1527, 1529, 1546, 1556, 1562, 1569, 1573, 1589, 1597, 1608, 1610, 1615, 1616, 1635, 1644, 1645, 1649, 1653, 1673, 1676, 1689, 1694, 1717, 1722, 1729, 1735, 1748, 1752, 1753, 1779, 1792, 1807, 1810, 1816, 1827, 1831, 1834, 1836, 1845, 1859, 1860, 1862, 1882, 1883, 1889, 1895, 1897, 1904, 1912, 1914, 1921, 1945, 1950, 1952, 1955, 1956, 1962, 1964, 2006, 2010, 2011, 2012, 2025, 2041, 2058, 2060, 2076, 2126, 2133, 2134, 2145, 2160, 2167, 2186, 2231, 2232, 2243, 2269, 2282, 2288, 2303, 2311, 2313, 2321, 2333, 2334, 2336, 2340, 2351, 2357, 2360, 2366, 2369, 2378, 2387, 2395, 2405, 2407, 2413, 2428, 2439, 2447, 2478, 2505, 2541, 2542, 2560, 2568, 2574, 2575, 2579, 2580, 2581, 2585, 2594, 2598, 2599, 2600, 2605, 2617, 2624, 2648, 2671, 2678, 2686, 2700, 2701, 2707, 2709, 2710, 2712, 2713, 2717, 2718, 2722, 2726, 2729, 2759, 2763, 2769, 2803, 2819, 2871, 2905, 2912, 2915, 2925, 2947, 2949, 2952, 2973, 2976, 2983, 2985, 2990, 2993, 3000, 3004, 3006, 3007, 3008, 3010, 3020, 3030, 3033, 3044, 3077, 3081, 3082, 3083, 3089, 3107, 3113, 3128, 3129, 3134, 3150, 3152, 3160, 3168, 3173, 3174, 3181, 3182, 3185, 3219, 3225, 3246, 3250, 3253, 3256, 3261, 3262, 3266, 3267, 3272, 3273, 3275, 3285, 3286, 3301, 3307, 3316, 3317, 3318, 3320, 3328, 3358, 3361, 3362, 3386, 3390, 3409, 3418, 3421, 3429, 3435, 3448, 3461, 3462, 3471, 3476, 3477, 3481, 3484, 3489, 3499, 3504, 3505, 3512, 3527, 3534, 3535, 3536, 3538, 3543, 3552, 3555, 3556, 3566, 3569, 3571, 3577, 3598, 3617, 3618, 3626, 3633, 3634, 3635, 3638, 3639, 3683, 3707, 3717, 3728, 3730, 3735, 3742, 3745, 3747, 3752, 3755, 3763, 3783, 3785, 3786, 3787, 3788, 3800, 3823, 3826, 3852, 3854, 3868, 3882, 3892, 3893, 3896, 3910, 3911, 3915, 3943, 3952, 3956, 3967, 3968, 3969, 3977, 3979, 3981, 3983, 3984, 3987, 3989, 3990, 3993, 3994, 3998, 3999, 4005, 4007, 4010, 4015, 4017, 4020, 4021, 4023, 4027, 4029, 4030, 4033, 4036, 4037, 4052, 4055, 4056, 4066, 4079, 4082, 4085, 4121, 4144, 4148, 4149, 4158, 4161, 4167, 4168, 4210, 4223, 4225, 4232, 4235, 4238, 4239, 4246, 4247, 4270, 4271, 4299, 4302, 4322, 4343, 4344, 4351, 4361, 4367, 4369, 4370, 4372, 4378, 4380, 4381, 4383, 4386, 4388, 4410, 4446, 4450, 4451, 4489, 4546, 4571, 4621, 4623, 4638, 4639, 4642, 4643, 4654, 4658, 4666, 4675, 4678, 4679, 4700, 4701, 4713, 4719, 4720, 4723, 4727, 4728, 4731, 4734, 4738, 4744, 4776, 4816, 4823, 4844, 4848, 4873, 4881, 4888, 4890, 4901, 4902, 4903, 4914, 4958, 4974, 4979, 4992, 5000, 5008, 5010, 5013, 5015, 5026, 5060, 5066, 5071, 5074, 5075, 5110, 5120, 5128, 5135, 5170, 5171, 5218, 5219, 5220, 5222, 5225, 5254, 5269, 5279, 5283, 5291, 5293, 5296, 5298, 5308, 5313, 5319, 5339, 5346, 5363, 5364, 5377, 5388, 5391, 5400, 5410, 5416, 5418, 5419, 5444, 5449, 5458, 5459, 5463, 5477, 5478, 5481, 5500, 5502, 5504, 5507, 5508, 5515, 5524, 5528, 5541, 5553, 5568, 5577, 5617, 5618, 5620, 5662, 5673, 5791, 5792, 5809, 5872, 5878, 5893, 5902, 5903, 5909, 5945, 5954, 5956, 5957, 5959, 5968, 5991, 6003, 6016, 6025, 6037, 6059, 6155, 6157, 6180, 6188, 6203, 6271, 6281, 6283, 6287, 6296, 6299, 6303, 6327, 6331, 6333, 6365, 6380, 6385, 6433, 6440, 6442, 6464, 6503, 6534, 6537, 6539, 6547, 6552, 6586, 6593, 6620, 6641, 6650, 6708, 6754, 6773, 6783, 6787, 6816, 6820, 6863, 6867, 6873, 6875, 6885, 6932, 6934, 6936, 6944, 6947, 6953, 6957, 6961, 6975, 6978, 6979, 6989, 7003, 7004, 7008, 7010, 7028, 7034, 7123, 7132, 7147, 7156, 7162, 7173, 7199, 7254, 7265, 7293, 7317, 7323, 7325, 7327, 7346, 7348, 7371, 7373, 7444, 7445, 7451, 7458, 7484, 7487, 7560, 7569, 7573, 7698, 7792, 7925, 8011, 8264, 8360, 8361, 8366, 8528, 8529, 8531, 8581, 8582, 8623, 8638, 8641, 8645, 8665, 8781, 8798, 8807, 8865, 8910, 8914, 8917, 8930, 8948, 8949, 8950, 8957, 8958, 8961, 8970, 8972, 8974, 8984, 26131, 26152, 26587, 26729, 26810, 27020, 27478, 27660, 27773, 27821, 27846, 27904, 30810, 30812, 30825, 31685, 31696, 33004, 33154, 34048, 34072, 34150, 34319, 34334, 34405, 34542, 35957, 36517, 36529, 37386, 37729, 37741, 38061, 38886, 39292, 40815, 41997, 42718, 44195, 44199, 44555, 44597, 44665, 44761, 44788, 45186, 45447, 45499, 45517, 45666, 45672, 45720, 45722, 45728, 45950, 46530, 46578, 46723, 46970, 46972, 46976, 47610, 47999, 48043, 48082, 48394, 48774, 48780, 49272, 49278, 49286, 50851, 50872, 51080, 51255, 51540, 51662, 52245, 52328, 52604, 52722, 52973, 53322, 53464, 53894, 53972, 53996, 54001, 54272, 54372, 54503, 54881, 55247, 55269, 55276, 55442, 55765, 55820, 55830, 56174, 56367, 56563, 56775, 56782, 57368, 57640, 57669, 58025, 58998, 59126, 59315, 59369, 59519, 59615, 59784, 59900, 60037, 60040, 60069, 60072, 60074, 60126, 60295, 60684, 60766, 61024, 61132, 61323, 61394, 62374, 62434, 62511, 63082, 63113, 63131, 63859, 64620, 64839, 64957, 65642, 65802, 66097, 66130, 66203, 66596, 66665, 66934, 67087, 67193, 67665, 67734, 67997, 68157, 68159, 68237, 68319, 68324, 68358, 68791, 68793, 68954, 69122, 69306, 69406, 69436, 69481, 69524, 69526, 70286, 70293, 70336, 70697, 70862, 71264, 71282, 71462, 71464, 71535, 71838, 72011, 72226, 72378, 72998, 73017, 73344, 74458, 74649, 74795, 74851, 76077, 76093, 76251, 76293, 76738, 77364, 77561, 78209, 78469, 78574, 79057, 79185, 79242, 79293, 79428, 79695, 79702, 80126, 80185, 80463, 80862, 81191, 81229, 81591, 81782, 81845, 81847, 81932, 82461, 82854, 83270, 83293, 83349, 83613, 83827, 84152, 84374, 84392, 84954, 85414, 85774, 86190, 86332, 86644, 86781, 86833, 86882, 86898, 86911, 87222, 87232, 87304, 87306, 87430, 87485, 87520, 87869, 87930, 88140, 88163, 88356, 88744, 88950, 89090, 89337, 89470, 89492, 89745, 89840, 90249, 90266, 90428, 90439, 90531, 90600, 90603, 90647, 90746, 90866, 90870, 91505, 91535, 91542, 91630, 91653, 91658, 91842, 91869, 92420, 92507, 93326, 93510, 93721, 93831, 93840, 94015, 94018, 94478, 94677, 94777, 94780, 94833, 94864, 94959, 95105, 95167, 95199, 95311, 95443, 95510, 95558, 95875, 96150, 96488, 96610, 96667, 96737, 97304, 97393, 97866, 97913, 97923, 98122, 98154, 98809, 98961, 99007, 99112, 99114, 99149, 99468, 99811, 100032, 100083, 100365, 100383, 100517, 100556, 100581, 100714, 100745, 101076, 101112, 101362, 101864, 101895, 102123, 102125, 102445, 102800, 102880, 102903, 103042, 103228, 103249, 103253, 103372, 103810, 104211, 104241, 104272, 104726, 104879, 105504, 106072, 106111, 106332, 106489, 106782, 106916, 106920, 107348, 107406, 107910, 108188, 108190, 108689, 108729, 108932, 108945, 109187, 109374, 109487, 109673, 109687, 109848, 110102, 110127, 110553, 110730, 110771, 111228, 111360, 111362, 111364, 111443, 111622, 111759, 111781, 112138, 112171, 112183, 112370, 112552, 112556, 112623, 112788, 112852, 112940, 113345, 113348, 113378, 113741, 114180, 114635, 115149, 115502, 115569, 115617, 115713, 116161, 116797, 116799, 116823, 116897, 117176, 117529, 117533, 118696, 119141, 119145, 120466, 120799, 121171, 121231, 122882, 122886, 122890, 122892, 122900, 122902, 122904, 122920, 122924, 127136, 128360, 129937, 130452, 130490, 130576, 130634, 131013, 132046, 132480, 132796, 132961, 134130, 134368, 134393, 134853, 135133, 135436, 135567, 135569, 136020, 136562, 136864, 137337, 137857, 138036, 139385, 139644, 139757, 139855, 140110, 140174, 140267, 140711, 140928, 142488, 142507, 143385, 145839, 145935, 146656, 148626, 149352, 149354, 149406, 152057, 152077, 152079, 152081, 155820, 156607, 156609, 157200, 157296, 157667, 158238, 158528, 159093, 159690, 159755, 159858, 159972, 160080, 160271, 160563, 160565, 160567, 161155, 337, 4231, 4772, 29, 194, 348, 482, 492, 714, 928, 930, 942, 965, 1104, 1175, 1232, 1237, 1241, 1245, 1255, 1348, 1570, 1627, 1809, 2066, 2067, 2117, 2118, 2159, 2204, 2606, 2672, 2677, 2892, 3018, 3503, 3676, 4404, 4437, 4552, 4645, 4725, 5017, 5054, 5062, 5072, 5105, 5137, 5316, 5574, 5608, 5686, 5782, 5853, 5867, 5881, 5949, 6140, 6197, 6214, 6242, 6294, 6322, 6323, 6383, 6530, 6538, 6584, 6643, 6666, 6757, 6774, 6777, 6790, 6858, 6971, 6987, 6993, 7013, 7022, 7044, 7068, 7069, 7084, 7115, 7116, 7135, 7163, 7223, 7587, 7700, 7728, 7771, 7827, 7981, 7982, 7991, 8195, 8228, 8370, 8477, 8600, 8620, 8690, 8783, 8928, 8973, 8983, 27266, 27317, 27604, 27721, 27788, 27834, 31410, 31878, 31952, 33615, 33683, 34437, 7, 9, 18, 74, 76, 79, 81, 85, 86, 92, 100, 140, 376, 640, 653, 707, 719, 743, 765, 818, 849, 852, 880, 4, 23, 35, 42, 48, 57, 58, 63, 64, 89, 97, 105, 122, 154, 159, 166, 177, 179, 202, 206, 209, 229, 249, 262, 269, 276, 281, 283, 326, 328, 332, 334, 340, 346, 354, 361, 365, 366, 369, 379, 383, 407, 412, 423, 428, 445, 448, 450, 451, 456, 465, 475, 479, 491, 493, 501, 504, 507, 513, 517, 519, 522, 547, 580, 599, 612, 662, 703, 891, 898, 902, 915, 917, 929, 933, 940, 950, 951, 954, 955, 966, 968, 969, 982, 1013, 1019, 1023, 1042, 1082, 1086, 1090, 1091, 1103, 1124, 1126, 1128, 1130, 1161, 1185, 1216, 1227, 1238, 1253, 1261, 1268, 1269, 1274, 1286, 1292, 1299, 1306, 1321, 1327, 1336, 1345, 1347, 1350, 1354, 1381, 1382, 1389, 1441, 4970, 905, 1907, 1960, 2013, 2690, 3196, 3406, 5380, 5747, 6201, 6516, 6753, 7212, 7841, 8191, 8493, 8611, 26111, 31116, 32469, 38038, 47721, 51471, 54259, 58047, 58299, 64285, 181, 393, 553, 918, 921, 945, 948, 952, 1012, 1135, 1224, 1256, 1296, 1301, 1346, 1395, 1427, 315, 1641, 1693, 1769, 1799, 2301, 2402, 2431, 2459, 2953, 3213, 3355, 3438, 3697, 4105, 6286, 6541, 6893, 7360, 7454, 7482, 8947, 31184, 20, 24, 224, 236, 425, 532, 605, 668, 670, 841, 900, 949, 971, 1078, 1096, 1188, 1202, 1277, 1305, 1438, 1515, 1797, 1835, 1873, 1900, 1927, 1931, 1932, 1935, 1941, 1944, 1946, 1947, 1949, 1951, 1957, 1958, 1959, 2022, 2027, 2068, 2132, 2176, 2178, 2181, 2183, 2203, 2205, 2361, 2474, 2644, 2721, 2728, 2730, 2731, 2739, 2746, 2805, 2932, 2970, 3053, 3067, 3088, 3095, 3100, 3155, 3159, 3201, 3245, 3248, 3252, 3310, 3365, 3371, 3405, 3415, 3468, 3475, 3498, 3546, 3559, 3629, 3668, 3681, 3736, 3741, 3992, 4008, 4103, 4267, 4278, 4282, 4297, 4312, 4359, 4432, 4458, 4564, 4857, 4865, 4967, 4976, 4978, 5014, 5073, 5096, 5114, 5147, 5177, 5304, 5348, 5367, 5373, 5385, 5446, 5470, 5489, 5599, 5633, 5682, 5810, 5882, 5940, 5971, 5992, 6001, 6008, 6162, 6235, 6404, 6415, 6591, 6599, 6611, 6669, 6709, 6796, 6807, 6881, 6890, 6918, 6954, 6981, 6982, 6985, 7038, 7042, 7063, 7070, 7072, 7088, 7104, 7136, 7139, 7160, 7161, 7234, 7347, 7419, 7713, 7748, 7759, 7766, 7942, 8019, 8042, 8125, 8154, 8239, 8338, 8507, 8656, 8955, 8966, 25753, 25769, 25805, 26052, 26242, 27803, 30820, 31101, 31658, 32892, 33162, 33903, 34143, 34326, 36535, 37733, 37736, 39183, 39231, 39869, 40278, 40629, 41285, 41571, 41863, 42004, 42418, 42734, 44204, 1034, 78, 842, 1409, 69, 3744, 27376, 27831, 37731, 49530, 52952, 53129, 55118, 55167, 55280, 59387, 62849, 65514, 70533, 73587, 82459, 92259, 73, 1892, 2356, 1300, 1366, 2202, 2300, 2470, 2583, 2662, 1681, 2065, 2367, 2384, 2942, 3720, 5065, 27822, 73268, 8, 118, 203, 227, 228, 254, 368, 413, 419, 424, 426, 432, 459, 463, 472, 477, 518, 523, 581, 767, 782, 806, 869, 947, 996, 1006, 1010, 1017, 1018, 1025, 1081, 1114, 1181, 1226, 1352, 1390, 1399, 1422, 1440, 1461, 1488, 1508, 1523, 1566, 1588, 1598, 1614, 1620, 1624, 1672, 1686, 1701, 1711, 1726, 1783, 1785, 1791, 1798, 1864, 1943, 1965, 1982, 2009, 2015, 2024, 2070, 2082, 2083, 2088, 2112, 2116, 2120, 2121, 2122, 2136, 2146, 2148, 2166, 2184, 2188, 2236, 2240, 2245, 2247, 2252, 2253, 2255, 2264, 2267, 2286, 2296, 2307, 2320, 2346, 2347, 2352, 2374, 2376, 2389, 2398, 2411, 2412, 2417, 2418, 2420, 2432, 2433, 2435, 2457, 2463, 2468, 2517, 2518, 2520, 2521, 2523, 2524, 2530, 2531, 2532, 2533, 2535, 2561, 2577, 2611, 2639, 2641, 2642, 2664, 2687, 2688, 2738, 2741, 2749, 2750, 2757, 2782, 2787, 2790, 2793, 2794, 2802, 2829, 2851, 2852, 2856, 2875, 2883, 2917, 2929, 2944, 2950, 2956, 2966, 2967, 2971, 2977, 2989, 3015, 3032, 3035, 3038, 3063, 3068, 3072, 3074, 3087, 3098, 3102, 3105, 3111, 3120, 3130, 3138, 3141, 3144, 3156, 3167, 3197, 3198, 3204, 3206, 3218, 3244, 3247, 3249, 3257, 3258, 3269, 3274, 3296, 3308, 3334, 3359, 3360, 3363, 3370, 3385, 3391, 3394, 3395, 3420, 3426, 3428, 3441, 3445, 3451, 3478, 3483, 3494, 3500, 3506, 3507, 3513, 3524, 3526, 3528, 3529, 3537, 3545, 3548, 3549, 3551, 3557, 3608, 3613, 3614, 3649, 3684, 3685, 3686, 3688, 3701, 3702, 3704, 3712, 3713, 3724, 3734, 3804, 3812, 3834, 3859, 3927, 3957, 4002, 4009, 4012, 4039, 4041, 4060, 4062, 4063, 4086, 4088, 4090, 4102, 4111, 4122, 4126, 4128, 4132, 4146, 4190, 4211, 4214, 4228, 4263, 4276, 4280, 4291, 4292, 4316, 4318, 4326, 4333, 4345, 4352, 4354, 4396, 4406, 4409, 4464, 4465, 4474, 4482, 4486, 4487, 4488, 4491, 4495, 4496, 4498, 4499, 4503, 4522, 4524, 4526, 4528, 4557, 4570, 4573, 4608, 4615, 4617, 4627, 4628, 4629, 4661, 4681, 4709, 4710, 4714, 4733, 4751, 4787, 4803, 4815, 4830, 4832, 4835, 4889, 4898, 4929, 4932, 4941, 4951, 4954, 4960, 4971, 5027, 5043, 5049, 5061, 5111, 5122, 5125, 5127, 5152, 5161, 5172, 5187, 5193, 5198, 5208, 5214, 5237, 5247, 5250, 5276, 5277, 5297, 5303, 5307, 5309, 5334, 5335, 5344, 5359, 5366, 5382, 5452, 5471, 5506, 5534, 5544, 5548, 5561, 5564, 5581, 5655, 5670, 5680, 5689, 5694, 5696, 5699, 5703, 5705, 5707, 5712, 5723, 5729, 5732, 5742, 5745, 5773, 5812, 5843, 5846, 5847, 5854, 5857, 5859, 5869, 5900, 5923, 5926, 5927, 5933, 5938, 5960, 5961, 5962, 6027, 6084, 6096, 6101, 6103, 6115, 6127, 6186, 6212, 6233, 6234, 6237, 6238, 6240, 6263, 6308, 6318, 6345, 6413, 6419, 6422, 6436, 6452, 6473, 6565, 1416, 3698, 74789, 204, 420, 88, 1359, 1760, 1974, 1983, 1984, 2107, 2170, 2507, 2689, 2888, 2891, 3568, 3858, 4016, 4248, 4251, 4340, 4452, 4483, 4502, 4509, 4558, 4622, 4649, 4652, 4662, 4809, 4956, 4988, 5106, 5282, 5483, 678, 1340, 2338, 2527, 2553, 2863, 2901, 2921, 2951, 3062, 3066, 3467, 3508, 3703, 3706, 3727, 3811, 3917, 838, 41, 55, 68, 147, 242, 256, 312, 321, 381, 469, 521, 1150, 1367, 3357, 3564, 4054, 4069, 2075, 2092, 2131, 3677, 4114, 4422, 4862, 4936, 6107, 7089, 7396, 7936, 7941, 8197, 48682, 59447, 69761, 71180, 76111, 89759, 96829, 97826, 98587, 100843, 101070, 102753, 103980, 105197, 105355, 105769, 107555, 110586, 188, 220, 285, 330, 338, 606, 611, 127202, 130, 327, 986, 1037, 1437, 1545, 1591, 1772, 1880, 2322, 2522, 2536, 2808, 3479, 3593, 3699, 3802, 3937, 4443, 4553, 4625, 4691, 4789, 4811, 4874, 5490, 5518, 5522, 5981, 6116, 6264, 6316, 6645, 6678, 6725, 6951, 7001, 7060, 7164, 7817, 8371, 8499, 8633, 8861, 69844, 837, 1457, 1612, 1806, 1821, 2004, 2390, 2496, 2622, 2836, 2879, 2978, 3189, 3254, 3450, 3515, 3525, 135, 637, 7064, 26151, 1707, 2153, 2379, 2381, 2383, 8387, 59018, 98124, 741, 5146, 5570, 5690, 6223, 6291, 6350, 6857, 7099, 7235, 7256, 7382, 8132, 8157, 8906, 8907, 8965, 26662, 26776, 27156, 27523, 27713, 27722, 27731, 27800, 27801, 27838, 27850, 27878, 30867, 31435, 32031, 32554, 32562, 34323, 36276, 37830, 41769, 42723, 44022, 44397, 44633, 44828, 44974, 45431, 46948, 47099, 47124, 47404, 48414, 48982, 48997, 50583, 50601, 52281, 52287, 52319, 52458, 53121, 53326, 53460, 53519, 53883, 54995, 55444, 55768, 55814, 55908, 55995, 56069, 56095, 56145, 56339, 56607, 56757, 56908, 57274, 57453, 57504, 57980, 58347, 58554, 59118, 59141, 59684, 60161, 60291, 60763, 61240, 62203, 62250, 62956, 62999, 63808, 64575, 64716, 64969, 64983, 64993, 65037, 65261, 66371, 67197, 67255, 67408, 68945, 69644, 69712, 70159, 70567, 71033, 71057, 71379, 71468, 71520, 71579, 71899, 72104, 72209, 72393, 72731, 72741, 73321, 73392, 73664, 73881, 74228, 74677, 76173, 77307, 77427, 77837, 79029, 79091, 79357, 79868, 80586, 80831, 81018, 81564, 82667, 83132, 83134, 83803, 84187, 84772, 84944, 84952, 85412, 85510, 85736, 85788, 85796, 86298, 86347, 86721, 89837, 90469, 91414, 92058, 93272, 93838, 95375, 95543, 95858, 96281, 96606, 96821, 97188, 97225, 97752, 97921, 97957, 98056, 98243, 99145, 101142, 103299, 103335, 103688, 106002, 106204, 106696, 107769, 107953, 109578, 109846, 109850, 110501, 110591, 110655, 111659, 112175, 112515, 114935, 115534, 115624, 258, 303, 421, 688, 897, 976, 1085, 2287, 2414, 2430, 2471, 2537, 2669, 2748, 2815, 2816, 2817, 2941, 3412, 3417, 3519, 3628, 3643, 3836, 3959, 4042, 4047, 1636, 1888, 1948, 2670, 461, 1969, 2408, 2806, 5525, 6058, 6370, 6776, 7615, 8918, 31408, 37727, 43744, 51094, 52545, 55451, 60950, 238, 392, 484, 1911, 1995, 2093, 2368, 3178, 3434, 3906, 4467, 26160, 26294, 44197, 48660, 56941, 58803, 69640, 77846, 91355, 96655, 65, 609, 761, 250, 2052, 3079, 3086, 3268, 3480, 3606, 3653, 3972, 4091, 4771, 5103, 5401, 5785, 5970, 6618, 6732, 7018, 7036, 7263, 26084, 26471, 27253, 32598, 33495, 33660, 33880, 34528, 48322, 48698, 50514, 52435, 53123, 53125, 54256, 55052, 55805, 56333, 57532, 60756, 65188, 70728, 71466, 72171, 72720, 73023, 74275, 74416, 74754, 74916, 79592, 79677, 80549, 81156, 83086, 83976, 84116, 85438, 86000, 86884, 87522, 88810, 88812, 90374, 90376, 90947, 91199, 93270, 93422, 93443, 93512, 94896, 95088, 95441, 96110, 96467, 96728, 96911, 97306, 97836, 99117, 99764, 99917, 100272, 101577, 102993, 103141, 103279, 103624, 104944, 105429, 105715, 105844, 106062, 106100, 106144, 106438, 107141, 107978, 108156, 110461, 111617, 112421, 113064, 113453, 113705, 113829, 113862, 114074, 114342, 127108, 127152, 127198, 127206, 128620, 131168, 133771, 134170, 139116, 140715, 141890, 142422, 148881, 155392, 160590, 635, 728, 1007, 1009, 1323, 1326, 1587, 1975, 1977, 1978, 1979, 1981, 1987, 1996, 2037, 2044, 2097, 2111, 2130, 2163, 415, 999, 1021, 2016, 2180, 2475, 2792, 2846, 3070, 3153, 3672, 3710, 7040, 26695, 34153, 3726, 7387, 8981, 801, 2123, 5693, 6743, 8544, 27706, 55566, 56030, 56171, 101947, 104374, 112290, 114662, 120637, 160438, 1015, 1105, 1474, 2393, 4846, 7318, 2456, 12, 28, 43, 279, 280, 294, 452, 613, 631, 650, 664, 694, 709, 711, 934, 2469, 2779, 4187, 6297, 26025, 26562, 31374, 45668, 374, 2059, 3821, 4254, 68554, 61, 667, 704, 810, 839, 3125, 3422, 3920, 3925, 3930, 3932, 3963, 3965, 3966, 53000, 54997, 15, 98, 239, 352, 409, 502, 510, 514, 575, 742, 1049, 1456, 1590, 1595, 1599, 1603, 1762, 1826, 1840, 1916, 1920, 1991, 2089, 2090, 2138, 2142, 2164, 2195, 2305, 2315, 2327, 2335, 2404, 2421, 2422, 2429, 2451, 2495, 2555, 2582, 2798, 2860, 2862, 2900, 2924, 2948, 2974, 3013, 3036, 3439, 3440, 3554, 3573, 3574, 3581, 3687, 3696, 3740, 3761, 3843, 3950, 3955, 3961, 3962, 3970, 4135, 4255, 4275, 4415, 4438, 4441, 4444, 4454, 4519, 4533, 4577, 4614, 4618, 4619, 4624, 4697, 4775, 4800, 4855, 4899, 4915, 4980, 4987, 4989, 5025, 5040, 5055, 5094, 5139, 5151, 5159, 5165, 5205, 5210, 5244, 5294, 5329, 5540, 5572, 5585, 5621, 5666, 5691, 5734, 5735, 5736, 5737, 5746, 5942, 5943, 5955, 6156, 6213, 6298, 6338, 6379, 6548, 6559, 6564, 6566, 6582, 6595, 6602, 6615, 6659, 6664, 6695, 6707, 6731, 6755, 6803, 6887, 6888, 6902, 6952, 6977, 7007, 7045, 7046, 7117, 7137, 7285, 7308, 7324, 7367, 7411, 7481, 7701, 7743, 7802, 7842, 7844, 7845, 7846, 7915, 7976, 7984, 7987, 8131, 8340, 8363, 8372, 8373, 8526, 8640, 8810, 8811, 8854, 8859, 25962, 26258, 26403, 26480, 26547, 26585, 26603, 26606, 26684, 26704, 26736, 26842, 27002, 27022, 27032, 27109, 27555, 27611, 27646, 27704, 27772, 27778, 27793, 27808, 31150, 31225, 31290, 31422, 31431, 32352, 32387, 32596, 33164, 33171, 33834, 34530, 36519, 36708, 39381, 39446, 40574, 40732, 42011, 42725, 43838, 43919, 43921, 43936, 44245, 44972, 45183, 45506, 45726, 46322, 46335, 46337, 46865, 46965, 47200, 47640, 47815, 47997, 48304, 48591, 48696, 48744, 48877, 49526, 49528, 49649, 49651, 49817, 50641, 50651, 50794, 50798, 50806, 51277, 51931, 51937, 52462, 53318, 53468, 53550, 54190, 54290, 54331, 54648, 54745, 55094, 55207, 55232, 55245, 55290, 55577, 55721, 56003, 56251, 56587, 56801, 57528, 58146, 58293, 58301, 58315, 58351, 58627, 58975, 59014, 59022, 59995, 60293, 60487, 60609, 60753, 61248, 61348, 62394, 62801, 62912, 63072, 63540, 63826, 63876, 63992, 64197, 64508, 64900, 65126, 65310, 65982, 66066, 66090, 66297, 66335, 67252, 67695, 67923, 68073, 68444, 68901, 68952, 68959, 68965, 69685, 69746, 70465, 70946, 71106, 71135, 71248, 71429, 71533, 71745, 72603, 72641, 72733, 73759, 74545, 74944, 74948, 75813, 76060, 76272, 77800, 77866, 78266, 78349, 78772, 79008, 79251, 79274, 79553, 79720, 79879, 80083, 80219, 80693, 80846, 81083, 81660, 81788, 82041, 82527, 85342, 85401, 85881, 86142, 87192, 87234, 87298, 88118, 89039, 89085, 89343, 89774, 89864, 90430, 91485, 91976, 92309, 93320, 93855, 94070, 95147, 95165, 95182, 95473, 95475, 95499, 95780, 95782, 95963, 95965, 96004, 96007, 96432, 96588, 96811, 97860, 98607, 98829, 99728, 100159, 101525, 102033, 102194, 102252, 102407, 102716, 103048, 103384, 103772, 104913, 105213, 106022, 106491, 106918, 107069, 107999, 108090, 108583, 108981, 109074, 109895, 110348, 110882, 111624, 111921, 112818, 113252, 113573, 114060, 114670, 115122, 115216, 115877, 115881, 116397, 117123, 118082, 126006, 130642, 130682, 135887, 139130, 141718, 141866, 152091, 152844, 156726, 159462, 161594, 162376, 2106, 2549, 4799, 8985, 42002, 44694, 2275, 2450, 3264, 3397, 3398, 4040, 4092, 6093, 6305, 6662, 6811, 7236, 7649, 7708, 7810, 7811, 7812, 8537, 26492, 26700, 27685, 31221, 37857, 47423, 47518, 1586, 2297, 3908, 5784, 6793, 7566, 26712, 38499, 43679, 50658, 50740, 50742, 51935, 52767, 65130, 70678, 97673, 42738, 45081, 46, 93, 156, 191, 783, 190, 495, 872, 1132, 1913, 2673, 3637, 3814, 4334, 4470, 4928, 5028, 5530, 5668, 6123, 6301, 6509, 7172, 7460, 7564, 7574, 7786, 7820, 7938, 7979, 8014, 8199, 8327, 8367, 8485, 26150, 26228, 26318, 26326, 26578, 31437, 31524, 31930, 40491, 43899, 45000, 47274, 48165, 52528, 52617, 52885, 53447, 58425, 61206, 64701, 68137, 68967, 69516, 71108, 71438, 78836, 81054, 81786, 205, 351, 2155, 2359, 3022, 3037, 4174, 4688, 5602, 3980, 33646, 234, 255, 275, 291, 437, 546, 548, 30, 72, 116, 121, 124, 171, 178, 213, 218, 263, 287, 290, 299, 302, 305, 324, 331, 427, 444, 446, 568, 633, 753, 756, 766, 828, 830, 844, 892, 1046, 1163, 2962, 51705, 52668, 62344, 63515, 66198, 67799, 1351, 1472, 1554, 747, 2380, 2382, 3387, 4084, 6482, 6550, 6763, 43836, 52694, 54732, 66798, 78041, 82852, 94466, 96616, 103341, 103883, 104218, 116977, 132157, 455, 27790, 54328, 84304, 40414, 48738, 58706, 63062, 64622, 174, 360, 879, 1322, 1330, 1655, 1970, 1971, 1972, 1973, 1985, 1988, 2026, 2069, 2113, 2119, 2149, 2279, 2443, 2445, 2461, 2462, 2465, 2485, 2789, 2868, 2928, 3017, 3024, 3051, 3203, 3660, 3693, 3709, 3764, 3840, 3877, 3918, 4081, 4124, 4140, 4205, 4213, 4222, 4266, 4480, 4490, 4501, 4516, 4520, 4560, 4561, 4636, 4670, 4682, 4949, 5080, 5203, 5292, 5342, 5343, 2208, 3739, 6254, 6273, 7056, 7831, 8094, 8128, 8629, 8765, 25850, 25868, 25947, 30712, 32525, 47202, 7081, 7154, 8522, 8969, 25801, 56949, 64034, 148888, 149830, 156025, 1014, 1083, 1619, 1670, 1937, 2099, 2135, 2436, 2442, 2565, 2801, 3186, 26701, 56921, 37, 117, 417, 506, 927, 973, 1057, 1192, 1273, 1279, 1341, 1384, 1420, 1516, 1535, 1594, 1648, 1734, 1788, 1841, 1856, 1924, 1929, 1939, 1966, 1999, 2043, 2137, 2219, 2227, 2290, 2312, 2345, 2362, 2397, 2453, 2548, 2725, 2747, 2764, 2784, 2820, 2844, 2859, 2866, 2919, 2920, 2922, 3011, 3061, 3093, 3145, 3163, 3223, 3224, 3327, 3329, 3342, 3350, 3469, 3511, 3521, 3544, 3547, 3550, 3565, 3588, 3590, 3591, 3609, 3655, 3675, 3678, 3679, 3680, 3700, 3708, 3729, 3733, 71, 4475, 5700, 6996, 8093, 5628, 65682, 84844, 129354, 458, 1187, 1392, 1480, 1727, 1801, 1846, 3127, 3271, 3584, 3682, 3946, 4203, 4218, 4234, 4407, 4479, 4572, 4673, 4837, 5003, 5180, 5302, 5447, 6104, 6125, 6344, 6898, 6997, 7005, 7017, 7149, 7193, 7272, 7836, 1992, 5422, 7773, 39408, 39416, 44731, 51086, 54281, 59306, 132, 257, 378, 489, 542, 932, 1460, 1593, 1658, 1688, 1804, 1863, 2330, 2558, 2563, 3270, 3835, 4130, 4219, 4221, 4304, 4357, 4545, 4600, 4677, 4757, 5255, 5438, 5505, 5829, 6183, 6375, 6480, 6638, 6744, 6850, 6974, 7101, 7255, 8709, 2719, 43396, 47148, 50685, 89804, 1683, 2349, 2613, 3200, 3615, 3725, 3732, 3738, 3760, 3769, 3789, 3806, 3810, 3816, 443, 870, 881, 943, 1063, 1112, 1317, 1379, 1429, 1518, 1564, 1606, 1613, 1646, 1678, 1702, 1713, 1824, 1833, 1848, 1852, 1866, 1885, 1894, 2053, 2071, 2101, 2104, 2306, 2337, 2365, 2373, 2375, 2425, 2440, 2498, 2587, 2590, 2660, 2828, 3099, 3194, 3330, 3379, 3388, 3414, 3457, 3490, 3563, 3654, 3889, 3895, 3926, 3928, 3929, 4106, 4139, 4179, 4186, 4195, 2416, 4220, 7616, 1976, 3857, 4492, 4493, 37475, 66659, 217, 313, 516, 558, 1064, 1487, 1667, 2017, 2162, 2316, 2385, 2540, 2620, 2906, 3299, 3400, 3553, 3594, 3743, 3824, 3953, 3978, 4155, 4699, 4745, 4756, 4814, 4821, 4867, 4977, 5108, 5164, 5312, 5387, 5415, 5612, 5677, 3616, 3691, 2151, 2745, 5016, 6768, 6782, 6791, 7247, 8169, 8580, 8879, 40959, 3991, 4031, 1111, 2843, 3456, 4964, 6211, 6571, 7349, 8012, 27178, 27255, 27727, 39768, 41527, 42935, 53189, 55555, 56274, 57243, 57792, 67267, 74486, 6724, 40870, 43376, 63853, 72395, 73290, 80969, 85612, 86880, 102792, 106441, 107559, 116939, 2492, 2504, 4427, 4833, 27751, 53953, 62049, 68135, 74324, 97757, 27, 102, 754, 1099, 6535, 6663, 6794, 34332, 1537, 77658, 89904, 4290, 4394, 4532, 5360, 97895, 103801, 106540, 2262, 4686, 4784, 4834, 39414, 59945, 66915, 71102, 71460, 1665, 5944, 6170, 6195, 6269, 6561, 4755, 7316, 7380, 56152, 61071, 65193, 86377, 90061, 92535, 100034, 103539, 104069, 117444, 544, 809, 829, 1005, 1668, 1746, 2567, 3452, 3466, 3509, 3975, 4153, 4229, 4265, 4616, 4866, 5081, 5093, 6250, 6265, 6764, 7381, 7439, 7570, 8010, 8614, 8968, 27338, 6300, 8117, 47491, 760, 1498, 2562, 5099, 5605, 5841, 2401, 1572, 2363, 2810, 30745, 31364, 32078, 32840, 42632, 47937, 55684, 58376, 59814, 61160, 71304, 73808, 76091, 80350, 81417, 82242, 85179, 86320, 86345, 86892, 2643, 4327, 6786, 490, 2736, 3430, 3690, 66544, 74688, 82202, 91077, 92751, 104337, 104925, 26974, 470, 834, 1430, 1447, 1490, 1532, 1632, 1661, 1739, 1886, 2449, 2799, 2845, 2979, 3046, 3437, 3774, 3914, 3973, 4217, 4630, 4732, 4749, 4750, 4765, 4875, 4968, 5053, 5095, 5323, 5443, 5448, 5501, 5531, 5556, 5562, 5569, 5597, 5609, 5615, 5625, 5765, 5880, 5883, 5901, 6057, 6063, 6204, 6284, 6587, 6827, 6872, 6909, 7189, 7315, 7343, 7899, 8130, 8225, 8534, 8667, 8720, 8832, 8835, 8836, 8839, 8860, 8864, 8870, 8908, 8911, 8937, 9010, 9018, 27869, 31445, 31724, 3404, 6596, 6686, 259, 358, 384, 391, 505, 569, 639, 274, 8643, 8808, 8982, 26198, 36525, 42732, 54736, 61729, 64249, 1003, 1542, 199, 2077, 2084, 4459, 5460, 5839, 5840, 6006, 3054, 3997, 27689, 27815, 30816, 36401, 40597, 43419, 44849, 45880, 52579, 54999, 59333, 60397, 63276, 66317, 66808, 69275, 70183, 72737, 73319, 77201, 80864, 82167, 82463, 86835, 89102, 89761, 90405, 93805, 94480, 99320, 66, 200, 240, 422, 512, 600, 691, 798, 861, 882, 1055, 1647, 1750, 7158, 7386, 700, 13, 146, 195, 201, 243, 270, 271, 343, 687, 835, 3646, 418, 2128, 4366, 4655, 7002, 705, 4389, 5379, 6040, 6187, 6207, 6493, 6930, 7541, 7624, 8129, 8857, 26116, 26133, 26422, 27674, 31114, 33669, 34164, 34532, 40826, 43177, 44709, 49280, 51174, 54004, 56169, 59418, 61075, 61401, 62437, 63479, 867, 1024, 1623, 2147, 2392, 2676, 2771, 2772, 2882, 3001, 3177, 3238, 3326, 3765, 3766, 3771, 3807, 2310, 2434, 2607, 2629, 2630, 2975, 3117, 957, 722, 944, 960, 1583, 1938, 2182, 2476, 2870, 2946, 2988, 3076, 3122, 3135, 3341, 3364, 3427, 3432, 3516, 3705, 3754, 2889, 3115, 3118, 3501, 3572, 3579, 3620, 3669, 3689, 295, 3470, 5876, 1165, 2913, 3576, 4735, 4887, 5046, 6826, 7048, 7282, 8403, 8654, 8790, 26554, 27005, 27410, 27728, 27922, 32825, 33558, 42197, 51357, 52606, 53207, 53956, 54771, 55363, 56788, 58432, 59590, 59810, 60943, 62792, 63436, 63481, 65133, 66509, 67867, 68194, 68205, 68932, 69278, 71156, 72129, 73211, 73929, 74452, 74532, 74685, 75985, 76210, 78034, 78160, 78218, 78544, 79006, 79134, 79796, 80363, 81535, 83506, 84395, 84601, 84615, 85020, 85022, 85025, 85131, 86290, 88405, 88785, 89753, 90345, 103235, 112112, 6889, 7155, 8369, 8604, 26686, 26999, 27193, 27482, 33499, 33836, 36289, 42015, 45732, 57353, 58103, 74946, 78637, 87975, 91978, 136592, 416, 8666, 8827, 27882, 1998, 3401, 3768, 4317, 4466, 4566, 4589, 4767, 4945, 5141, 5910, 48872, 4531, 8751, 8754, 8838, 8899, 27839, 32296, 39715, 40339, 43928, 45501, 45730, 51412, 53993, 55282, 62081, 98491, 114552, 117851, 130073, 133419, 779, 26564, 45969, 51372, 59834, 70121, 71876, 4770, 37240, 1993, 627, 630, 685, 781, 848, 991, 3891, 3936, 4207, 4212, 5047, 5134, 5357, 5389, 5421, 5479, 5611, 5941, 5947, 5994, 7009, 7150, 7179, 7303, 7579, 7669, 7714, 7753, 8530, 8661, 8833, 8935, 8943, 8998, 25788, 26680, 26870, 31193, 31694, 32174, 33621, 39234, 39435, 40148, 43908, 43930, 44193, 47254, 47382, 49772, 49822, 49957, 51077, 51834, 52975, 54775, 55110, 55267, 55872, 56715, 57326, 58105, 58154, 59103, 59501, 60471, 62113, 70599, 72407, 72605, 72696, 74508, 76054, 2807, 2835, 4506, 4676, 4876, 6958, 6959, 8607, 8814, 26375, 27837, 32017, 32029, 33681, 34534, 37380, 40851, 42721, 43560, 45062, 46062, 47384, 47952, 49274, 50162, 50802, 51575, 51698, 51925, 52456, 52712, 52950, 53466, 54276, 55259, 55999, 56176, 56915, 57401, 57526, 57951, 58972, 59421, 59594, 60514, 60516, 60937, 61350, 61705, 62376, 62733, 64030, 64116, 64497, 65552, 65567, 65577, 65585, 65685, 66171, 68848, 69253, 69606, 69805, 69951, 70282, 70305, 71252, 71254, 71318, 71530, 72165, 72701, 72919, 73015, 73042, 74154, 74530, 74580, 74698, 75805, 78105, 78264, 78893, 79139, 79224, 80615, 81512, 81784, 82095, 83480, 85056, 85261, 86059, 87876, 88380, 88879, 89087, 91660, 91974, 92264, 92681, 95207, 96417, 96590, 97742, 98296, 100163, 100487, 100498, 101025, 103339, 103655, 104074, 104243, 104312, 106642, 108979, 109864, 114795, 118997, 130520, 1525, 2735, 2984, 8830, 6628, 7027, 8008, 30822, 414, 1839, 824, 1056, 1601, 1643, 1795, 1844, 2482, 2487, 2569, 2696, 2704, 2893, 3045, 3192, 3240, 3539, 3721, 3795, 3919, 4166, 4740, 901, 935, 938, 946, 956, 1936, 1940, 1942, 2201, 2612, 2927, 3199, 3540, 3567, 3580, 3656, 3657, 3714, 3716, 3723, 113, 731, 103, 347, 698, 4994, 37853, 50804, 56156, 65465, 2328, 2339, 2354, 2386, 48560, 111529, 473, 715, 888, 936, 961, 970, 984, 1066, 1162, 1401, 1419, 1455, 1703, 1925, 2173, 2238, 2241, 2285, 2370, 2399, 2615, 2732, 2899, 2904, 2938, 3028, 3069, 3090, 3091, 3142, 3143, 3165, 3235, 3260, 3284, 3313, 3347, 3368, 3392, 3425, 3447, 3492, 3520, 6460, 1432, 6780, 7075, 7826, 45928, 56885, 3502, 4563, 4880, 2177, 2200, 2940, 3097, 3306, 3632, 3872, 4273, 4420, 4768, 5009, 5333, 5440, 5498, 5613, 6126, 6609, 6721, 6920, 7209, 7210, 7211, 7215, 7577, 7926, 7943, 8188, 8584, 8670, 25952, 33145, 67788, 90576, 95309, 105246, 109483, 148956, 387, 433, 476, 486, 656, 725, 1431, 1468, 1495, 2040, 2266, 2331, 2473, 2552, 2597, 2774, 2796, 3715, 4089, 4115, 4180, 4293, 4355, 2187, 2935, 6412, 6877, 7061, 7078, 7121, 7437, 7493, 554, 695, 1404, 1425, 2272, 2415, 2570, 3106, 3109, 3110, 3214, 3259, 3694, 4356, 5433, 6243, 6808, 7809, 8253, 8589, 8596, 219, 1008, 1684, 3183, 4371, 6474, 1881, 487, 533, 692, 833, 1453, 1744, 2050, 2372, 2458, 2714, 3444, 4338, 4339, 4353, 4473, 4802, 4842, 4923, 4990, 5107, 59725, 65230, 150548, 72356, 95654, 37739, 184, 846, 2497, 2897, 5076, 5092, 6252, 8254, 31956, 38798, 50954, 55253, 55274, 5300, 6713, 7919, 8484, 25771, 26082, 26840, 26903, 30803, 64695, 101962, 2652, 4224, 2488, 2557, 2783, 2853, 2964, 3075, 3205, 3216, 3294, 3344, 3621, 3658, 3777, 3847, 3875, 4368, 4390, 4403, 4417, 4752, 4754, 4893, 4996, 5034, 5153, 5588, 5600, 5715, 5778, 5891, 5980, 6000, 6256, 6257, 6290, 6367, 6395, 6748, 6940, 7024, 7029, 7065, 7110, 7492, 7650, 7882, 7920, 8194, 8848, 25774, 25807, 26003, 26125, 26171, 26176, 26231, 26241, 26303, 26320, 26631, 26693, 27329, 27648, 27784, 27798, 30783, 31270, 31502, 32211, 32686, 32728, 32898, 33592, 33817, 33896, 40412, 40833, 45662, 48231, 48972, 51207, 51304, 52666, 53435, 55652, 57910, 58964, 59727, 60333, 64153, 66310, 69134, 69720, 71518, 71700, 74370, 76030, 76303, 80736, 80844, 81138, 87205, 88272, 89118, 90357, 91488, 92206, 92494, 92496, 92498, 96490, 96563, 96634, 96815, 97593, 98083, 99296, 99470, 99669, 99912, 100306, 104457, 104662, 105763, 106870, 107057, 107771, 108192, 108447, 108506, 110748, 111486, 112277, 112655, 112689, 113565, 113640, 113780, 114044, 114766, 116503, 117121, 117434, 118260, 118334, 118880, 121113, 130448, 131451, 132146, 133824, 136602, 140523, 141956, 151639, 152173, 3207, 4535, 4972, 6428, 6450, 7376, 8337, 26394, 499, 1191, 4593, 1633, 2847, 2969, 2972, 3171, 37384, 906, 1934, 2654, 4184, 7073, 7706, 8167, 8492, 25750, 27373, 31156, 65135, 83374, 85316, 85367, 85397, 86014, 86293, 86852, 87529, 88267, 89300, 48501, 68659, 73266, 80241, 81132, 95307, 101285, 108548, 111113, 114707, 115680, 117871, 135532, 139620, 147006, 147010, 147426, 148168, 149572, 105593, 107083, 107516, 114028, 116660, 59273, 60128, 74152, 79318, 93324, 95135, 97057, 104283, 133195, 136016, 136598, 141688, 146309, 80, 401, 615, 759, 4117, 4178, 5899, 6986, 7062, 7086, 7087, 7091, 7840, 7944, 8989, 4095, 1087, 3746, 4151, 4384, 5607, 6869, 7177, 7456, 7459, 8951, 27783, 32170, 34198, 1445, 1581, 1626, 2325, 3442, 3463, 3695, 3758, 577, 1592, 2525, 4045, 2051, 3287, 3674, 4795, 5480, 6163, 7374, 9001, 26528, 42191, 59392, 60674, 67295, 74282, 77435, 82173, 88345, 93061, 93265, 95313, 95377, 105468, 106011, 117192, 117895, 142997, 152017, 161944, 941, 7757, 8158, 8341, 3078, 4587, 6765, 31433, 4143, 4584, 5069, 619, 907, 1167, 1363, 1489, 2031, 2039, 2045, 2048, 2057, 2168, 2206, 2491, 2500, 2691, 2874, 2876, 2886, 2961, 3166, 3399, 3599, 3604, 3611, 3612, 3673, 3759, 3775, 3901, 3921, 3922, 3924, 3964, 4024, 4061, 4068, 4133, 4141, 4142, 4169, 4177, 4188, 4294, 4387, 4402, 4508, 4511, 4663, 4743, 4774, 4818, 4912, 5012, 5021, 5038, 5048, 5109, 5168, 5305, 5337, 5354, 5361, 5372, 5375, 5538, 5539, 5629, 6060, 6124, 6182, 6245, 6260, 6266, 6355, 6357, 6358, 6387, 6390, 6414, 6423, 6454, 6533, 6536, 6568, 6646, 6665, 6703, 6723, 6785, 6970, 6999, 7000, 7080, 7082, 7102, 7122, 7142, 7151, 7165, 7186, 7228, 7294, 7320, 7362, 7369, 7375, 7584, 7614, 7720, 7790, 7822, 7888, 7916, 8015, 8196, 8263, 8385, 8460, 8482, 8502, 8525, 8574, 8712, 8796, 8916, 8986, 8988, 8999, 9000, 25937, 25971, 26386, 31026, 32381, 33639, 44613, 45028, 1324, 7449, 8884, 32302, 6216, 7843, 8275, 78321, 31660, 32460, 62115, 74727, 98615, 102666, 107412, 118468, 121126, 127052, 136449, 158956, 488, 1137, 1652, 2864, 3221, 3459, 4500, 4518, 4612, 4863, 5275, 5473, 5780, 6021, 6114, 6121, 6132, 6465, 6730, 7505, 7764, 7878, 7889, 8126, 8189, 8240, 8800, 8872, 8892, 8893, 8923, 8938, 25744, 26164, 26494, 26524, 26655, 26749, 26809, 27322, 27792, 31682, 32515, 32735, 32797, 33021, 33138, 39659, 40226, 42900, 45521, 46544, 47465, 49902, 49932, 50011, 50912, 51380, 52831, 54785, 56079, 56286, 58520, 59339, 60384, 62764, 63836, 67957, 70994, 71390, 71494, 72109, 72880, 73531, 75349, 75823, 77291, 79203, 79686, 80217, 80553, 82150, 83829, 87884, 88106, 92424, 95113, 95115, 95752, 31284, 42351, 65665, 69849, 84506, 7300, 30846, 45172, 58303, 59731, 67508, 93040, 2943, 278, 436, 453, 498, 1184, 1963, 2171, 2254, 2257, 2546, 2618, 2848, 2884, 3094, 3384, 3393, 3436, 3531, 3846, 4424, 5768, 7934, 26513, 27899, 31923, 83, 155, 408, 603, 937, 962, 964, 972, 992, 1004, 1026, 1113, 1397, 1398, 1417, 1600, 2079, 4080, 4277, 4329, 4360, 4462, 4478, 4537, 4585, 4603, 4704, 5267, 5420, 5601, 5644, 5718, 5836, 6092, 6225, 6227, 6231, 6232, 6239, 6276, 6314, 6315, 6356, 6386, 6424, 6429, 6431, 6432, 6446, 6448, 6458, 6466, 6468, 6470, 6477, 6484, 6498, 6521, 6522, 6525, 6527, 6562, 6585, 6613, 6630, 6636, 6658, 6718, 6735, 6788, 6797, 6810, 6813, 6822, 6829, 6832, 6852, 6856, 7059, 7085, 7107, 7178, 7198, 7207, 7250, 7283, 7305, 7311, 7357, 7394, 7702, 7782, 7787, 7791, 7980, 8009, 8039, 8057, 8183, 8187, 8190, 8268, 8451, 8463, 8487, 8524, 8535, 8612, 8616, 8617, 8618, 8657, 8672, 8695, 8718, 8745, 8772, 8819, 8820, 8821, 8850, 8880, 8920, 8921, 8929, 9004, 9005, 32139, 45208, 99, 187, 363, 896, 1123, 1875, 2499, 6617, 6927, 8576, 8831, 8963, 33437, 45210, 115210, 127098, 5788, 5879, 5958, 6012, 6013, 6014, 6154, 129428, 1133, 26649, 68099, 149532, 5085, 7395, 7697, 301, 389, 1428, 1575, 5918, 5985, 50703, 74787, 89045, 141668, 6818, 55417, 4191, 4539, 1328, 5888, 74510, 104441, 104590, 121618, 5527, 6883, 36527, 53, 268, 632, 850, 981, 7366, 8207, 876, 1755, 2625, 2780, 2880, 3627, 3905, 4440, 4442, 4565, 4567, 4687, 4696, 4717, 4952, 5243, 5833, 6095, 6722, 8795, 26865, 31804, 1050, 2438, 1444, 4534, 5325, 4003, 32456, 62336, 85780, 98604, 103659, 104419, 115927, 2516, 4159, 4721, 4826, 4895, 5558, 5672, 5678, 5815, 5819, 5874, 6806, 6880, 6995, 7108, 7257, 7789, 7894, 26555, 31162, 31420, 32019, 34271, 34523, 36397, 37477, 40723, 43904, 47044, 50923, 56336, 2550, 5663, 7586, 32743, 8133, 710, 1414, 1526, 1602, 1629, 1642, 1837, 1855, 2095, 2098, 2261, 2265, 2472, 2506, 3042, 3043, 3497, 3600, 3622, 1446, 4296, 5643, 5684, 2446, 2486, 2545, 2626, 2775, 2894, 2939, 34321, 109249, 27251, 55732, 3819, 4305, 4626, 4632, 4664, 4680, 4705, 4706, 7093, 8689, 36509, 37720, 40614, 41716, 1756, 4349, 7379, 55498, 56633, 91690, 104303, 105585, 110352, 115170, 122888, 138208, 142448, 1067, 1922, 2073, 2246, 2589, 2733, 4284, 5324, 5414, 44225, 49647, 53974, 6710, 82931, 86504, 95873, 96373, 101741, 104863, 110645, 112804, 114265, 129653, 130580, 134569, 438, 1604, 2681, 2809, 2996, 5523, 5803, 8871, 8931, 8946, 26812, 27912, 33826, 34129, 34338, 34536, 38992, 39398, 40946, 48319, 49284, 49396, 51088, 51091, 55031, 55116, 58156, 58297, 58839, 59037, 61352, 62155, 70565, 70597, 71205, 71668, 71732, 72308, 72489, 74668, 75440, 78467, 78703, 79299, 80166, 80727, 80917, 81516, 81537, 82534, 83910, 84154, 84160, 85213, 87660, 88672, 89047, 89072, 90719, 91094, 91483, 91622, 92234, 92694, 93498, 94799, 94953, 95720, 98369, 99437, 100450, 101612, 102819, 111743, 131724, 135518, 135861, 697, 2197, 2364, 2448, 4569, 988, 2036, 5102, 6706, 8575, 8866, 32289, 34336, 39307, 41573, 42958, 43917, 45221, 46919, 46967, 48791, 51884, 58889, 59258, 61123, 68269, 68838, 78101, 78316, 79824, 80551, 80839, 82169, 89194, 91886, 990, 1497, 4200, 4660, 5915, 6249, 6800, 6835, 6868, 7448, 7767, 8799, 27851, 30848, 33688, 34520, 36533, 37382, 39444, 43932, 48142, 48518, 48596, 49314, 50147, 50189, 50442, 52460, 52644, 52717, 53999, 54787, 55261, 55272, 939, 1926, 1933, 2212, 2936, 2981, 3096, 3217, 3423, 3446, 3496, 3522, 3737, 3792, 5866, 49, 467, 787, 1699, 2169, 2250, 2271, 2280, 2314, 2494, 2610, 2885, 2930, 3241, 3902, 4035, 4391, 4737, 4783, 4965, 5315, 5417, 5425, 5808, 6159, 6215, 6337, 6384, 6612, 6760, 7025, 8527, 32298, 47629, 49824, 49961, 54, 813, 1410, 1463, 96, 1180, 1190, 1596, 58107, 5820, 5917, 4350, 5637, 5752, 5850, 6077, 6600, 6644, 7058, 7762, 7833, 8491, 8711, 8777, 8964, 25737, 25826, 25874, 25901, 26009, 26188, 26268, 26342, 26366, 26425, 27351, 27857, 27879, 31921, 32280, 32464, 32844, 33760, 42783, 53038, 53737, 54910, 60137, 60990, 66019, 68884, 69974, 70846, 74327, 78122, 84312, 241, 70344, 3934, 33830, 40581, 48520, 69069, 70663, 92509, 94325, 99813, 100527, 102720, 112006, 112767, 112897, 115147, 115664, 119155, 128512, 130087, 135137, 144620, 148652, 1349, 4885, 2207, 2621, 3822, 4806, 4861, 4933, 4947, 4957, 5097, 5383, 5603, 5622, 5651, 5796, 5799, 5801, 5873, 6032, 6078, 6166, 6178, 6219, 6261, 6405, 6426, 6447, 6461, 6518, 7774, 7832, 7834, 7835, 8542, 8610, 8675, 5475, 8933, 41336, 49394, 78903, 98126, 103444, 388, 1504, 1730, 1870, 2029, 2304, 2388, 2837, 3158, 3161, 3790, 3903, 5632, 6062, 6268, 309, 1051, 1919, 264, 1043, 439, 1507, 4181, 4527, 4550, 4559, 4578, 5646, 5834, 5969, 511, 5428, 7152, 8730, 30883, 4347, 31427, 31903, 33085, 5826, 7924, 8142, 25777, 27397, 27592, 48817, 62378, 72781, 77907, 79136, 91947, 94024, 94939, 97744, 99795, 6990, 30894, 33587, 48159, 54270, 57223, 58306, 61167, 64032, 65601, 71490, 71573, 72043, 72405, 72479, 72762, 73106, 73168, 74115, 74156, 74868, 75341, 85572, 1794, 2165, 2839, 3188, 3289, 4236, 4237, 4252, 4375, 4722, 4766, 4897, 5685, 5875, 6244, 6329, 6592, 6772, 6935, 6945, 7932, 8813, 8979, 26599, 30898, 31689, 32025, 33838, 47950, 49132, 51418, 55069, 58191, 61236, 61357, 68347, 69458, 72386, 91673, 103137, 113275, 115174, 4822, 51127, 8915, 1757, 5828, 6864, 7818, 26509, 26915, 42013, 44840, 45442, 48522, 7079, 7572, 30850, 679, 816, 893, 1609, 755, 1669, 2573, 2776, 106766, 3848, 3900, 4043, 4046, 4048, 4529, 4544, 4849, 5675, 59, 1759, 4969, 5083, 5365, 6005, 6122, 27873, 43869, 46347, 48741, 64114, 4000, 3202, 5056, 5121, 64660, 79469, 80717, 99030, 107447, 107649, 129313, 141886, 148372, 153584, 1865, 2693, 4067, 119, 375, 460, 536, 726, 1054, 1169, 1442, 1605, 1767, 1896, 2007, 2237, 2276, 2419, 2682, 2752, 2812, 3103, 3449, 3784, 3813, 3951, 4077, 4109, 4116, 4136, 4162, 4171, 4215, 4216, 4274, 4279, 4300, 4644, 4690, 4703, 4769, 4810, 4836, 4851, 4921, 4925, 5023, 5051, 5186, 5238, 5241, 5246, 5248, 5341, 5353, 5398, 5462, 5619, 5642, 5667, 5787, 5832, 5963, 6335, 6449, 6639, 6751, 6770, 6779, 6840, 6892, 6896, 6950, 6963, 7076, 7095, 7096, 7217, 7334, 7450, 7478, 7619, 7705, 8147, 8332, 8362, 8753, 8987, 25891, 26085, 26178, 31035, 31700, 32369, 106471, 106473, 106762, 107081, 390, 886, 5002, 7012, 7026, 26726, 32914, 56805, 69784, 78039, 82035, 88954, 95740, 102684, 102686, 102905, 103813, 106236, 106330, 108727, 110110, 120392, 126106, 128520, 133295, 145307, 145775, 152025, 1621, 4792, 5754, 6476, 6983, 7171, 8722, 42728, 42730, 4543, 5265, 341, 1236, 2062, 2154, 620, 963, 1069, 1076, 2035, 2210, 2221, 2727, 3002, 3136, 3140, 3232, 3309, 3314, 3640, 4405, 4515, 4998, 5001, 5059, 5202, 5288, 5404, 5434, 5604, 5914, 5932, 6148, 6198, 6400, 6408, 6513, 6579, 6739, 7043, 7074, 7195, 7196, 7238, 7309, 7407, 7897, 7914, 7939, 7983, 8235, 8257, 8267, 8336, 8423, 8511, 8609, 8684, 8700, 8797, 8840, 8882, 25752, 25755, 25764, 25827, 25839, 25916, 25993, 26122, 26302, 26313, 26391, 26400, 26414, 26850, 27334, 27816, 30723, 30818, 30892, 31547, 31549, 31737, 31770, 32160, 32371, 32853, 32882, 33312, 33380, 34583, 36553, 37785, 38304, 41226, 42163, 42681, 44587, 44671, 45837, 46664, 46850, 46974, 47152, 47287, 47714, 48198, 48301, 49225, 50259, 51044, 52241, 52967, 54419, 54426, 55063, 55071, 55687, 57972, 58879, 59832, 59846, 62383, 65638, 67504, 69241, 69604, 70488, 70927, 71525, 71650, 72176, 72626, 72647, 73276, 73572, 77359, 78517, 78829, 80572, 80599, 81910, 82934, 83096, 83318, 83322, 83359, 83361, 83411, 83603, 72612, 7051, 25763, 26265, 2214, 2514, 3849, 5830, 8404, 26007, 26393, 27075, 39052, 43391, 44301, 44317, 66246, 211, 449, 659, 769, 1310, 1413, 1796, 1861, 2554, 2609, 2627, 2697, 2824, 3057, 3133, 3304, 3718, 3913, 3947, 4197, 4562, 4698, 4711, 5018, 5022, 5226, 5256, 5285, 5825, 5965, 5993, 6042, 6185, 6368, 26172, 32582, 32632, 45440, 86548, 90403, 90890, 1903, 27423, 33158, 51939, 58655, 76175, 77206, 78088, 89030, 90524, 92938, 93766, 96691, 96863, 102481, 105755, 108928, 112911, 118900, 27867, 33672, 44511, 50445, 62644, 65088, 65216, 74740, 90888, 702, 3560, 5179, 5560, 7071, 26094, 26574, 31973, 32444, 42677, 44717, 49299, 50842, 56869, 57038, 59805, 63179, 64278, 68872, 71433, 71755, 72683, 85394, 86626, 88682, 89000, 89356, 90863, 92163, 96020, 96832, 97230, 98963, 100106, 103210, 108873, 111235, 112062, 112070, 129191, 130980, 131830, 138696, 138698, 1337, 1355, 2633, 2634, 2635, 2636, 2637, 2638, 2647, 2649, 2650, 2651, 2653, 2781, 8823, 7206, 7947, 144976, 304, 27186, 2715, 2758, 77, 559, 573, 681, 690, 721, 793, 820, 854, 1174, 1365, 1369, 1406, 1415, 1654, 1733, 528, 496, 4748, 62718, 63239, 63393, 69945, 2483, 25911, 43267, 46559, 59143, 60649, 71131, 74624, 77798, 78729, 80026, 82037, 1454, 1878, 2190, 4798, 6228, 7050, 7055, 7216, 50160, 567, 864, 889, 987, 997, 1145, 1482, 1501, 1631, 1660, 1910, 2323, 2437, 2441, 2481, 2511, 2674, 3180, 3302, 3860, 3880, 4761, 4782, 4961, 5258, 5868, 6279, 6306, 6339, 8364, 8927, 84, 696, 845, 1040, 2753, 126548, 38, 320, 69280, 251, 87, 564, 840, 885, 998, 1331, 1433, 1473, 1812, 1854, 1874, 1902, 2244, 2292, 2464, 2559, 2566, 2751, 2786, 2898, 3029, 3048, 3112, 5101, 5772, 7302, 102217, 118890, 120805, 128846, 129514, 130970, 136445, 136447, 140265, 4073, 5710, 26322, 26732, 66744, 81831, 91628, 93287, 95449, 95949, 96448, 97168, 101531, 103984, 4568, 6506, 48061, 59721, 60857, 71810, 651, 2526, 2656, 4911, 39427, 8208, 808, 2074, 2493, 3719, 4194, 4298, 4801, 4920, 5142, 5986, 6031, 6247, 6416, 6467, 8016, 8785, 25792, 25825, 25898, 26208, 26324, 26325, 26472, 26788, 27741, 31522, 32234, 34552, 46855, 53024, 60382, 112460, 61361, 1475, 2377, 626, 1582, 3064, 875, 3945, 4241, 31413, 61013, 64321, 64499, 64501, 75983, 108709, 121491, 126430, 2239, 746, 1068, 1152, 1153, 1154, 2049, 2056, 2260, 2283, 2631, 2755, 2878, 2937, 3121, 3211, 3292, 3340, 3343, 3377, 3380, 3731, 3833, 4098, 4108, 4123, 4175, 4183, 4185, 4281, 4332, 4392, 4414, 4426, 4428, 4433, 4523, 4555, 4590, 4606, 4659, 4667, 4674, 4684, 4692, 4716, 4831, 4840, 4859, 4927, 4948, 4999, 5004, 5033, 5087, 5088, 5098, 5119, 5199, 5242, 5384, 5450, 5521, 5638, 5641, 5777, 5795, 5936, 5966, 6047, 6051, 6064, 6100, 6105, 6109, 6133, 6230, 6341, 6410, 6528, 6603, 6629, 6671, 6676, 6684, 6728, 6851, 6906, 6964, 6992, 7020, 7023, 7067, 7083, 7111, 7125, 7126, 7130, 7131, 7180, 7182, 7190, 7219, 7222, 7248, 7266, 7354, 7358, 7415, 7571, 7583, 7585, 7613, 7620, 7636, 7815, 7872, 7881, 7883, 7921, 7922, 7935, 7946, 7948, 7958, 7959, 7995, 8003, 8033, 8044, 8056, 8123, 8137, 8261, 8266, 8331, 8388, 8392, 8410, 8420, 8422, 8459, 8462, 8465, 8571, 8572, 8583, 8625, 8650, 8724, 8725, 8727, 8752, 8761, 8763, 8768, 8828, 8851, 8853, 8903, 9012, 25773, 25795, 25828, 25841, 25842, 25856, 25865, 25882, 25886, 25900, 25904, 25906, 25920, 25929, 25930, 25940, 25941, 25945, 25965, 25972, 25996, 25999, 26010, 26013, 26079, 26086, 26093, 26117, 26147, 26157, 26163, 26180, 26199, 26229, 26251, 26271, 26323, 26338, 26346, 26349, 26350, 26371, 26404, 26430, 26435, 26467, 26485, 26487, 26501, 26505, 26581, 26622, 26689, 26694, 26731, 26737, 26775, 26782, 26784, 26797, 26835, 26838, 27802, 27812, 31104, 31109, 31747, 31963, 32022, 32203, 32349, 32943, 33358, 33912, 33917, 34002, 34018, 34359, 34364, 34608, 36152, 37211, 37277, 37855, 38994, 39419, 39779, 39941, 40817, 41714, 42740, 43333, 43351, 43635, 43708, 43910, 44073, 44421, 44759, 44864, 44911, 45179, 45382, 45679, 45942, 45987, 46561, 47092, 47196, 47261, 47330, 47493, 47606, 47894, 47978, 48262, 48268, 49220, 49910, 50245, 51773, 52378, 52913, 53133, 53887, 54220, 54513, 55078, 55156, 55757, 55851, 55895, 57418, 57430, 58365, 58649, 58904, 59180, 59669, 60135, 60343, 61634, 63629, 64229, 64338, 64990, 65418, 66200, 66686, 67429, 68536, 68614, 69559, 69654, 69821, 69908, 70188, 70201, 70418, 70751, 71404, 71804, 72131, 72169, 72367, 73323, 73469, 73854, 74089, 74630, 75990, 76763, 77421, 77808, 78111, 78116, 78653, 78967, 80346, 81641, 81898, 82378, 83332, 84098, 84847, 85016, 86487, 86864, 86982, 87218, 87383, 87598, 88024, 88235, 89203, 89260, 89321, 89408, 89678, 89881, 90057, 90717, 91134, 91286, 91582, 91610, 91890, 92756, 93432, 93700, 94266, 94931, 95583, 96075, 96314, 96565, 96792, 96849, 96901, 97254, 97395, 97639, 97817, 97936, 97994, 98441, 98458, 98473, 98611, 98795, 98803, 99085, 99089, 99220, 99270, 99273, 99276, 99741, 99839, 101088, 101106, 101850, 101904, 102396, 102588, 103107, 103671, 104119, 104321, 104339, 104595, 104597, 104757, 105211, 105731, 106004, 106397, 106452, 107042, 107382, 108076, 109161, 109205, 109740, 110194, 110453, 110752, 110858, 111384, 111795, 112334, 112399, 112450, 112577, 112582, 112653, 112735, 112850, 112921, 113207, 113220, 113938, 114082, 114122, 114464, 114601, 115231, 116012, 116136, 117456, 118898, 118924, 118985, 120821, 127114, 127158, 127164, 127178, 128606, 129364, 130351, 132074, 132496, 132888, 133645, 134025, 134881, 135508, 136018, 138258, 140247, 140816, 141749, 142192, 142258, 143377, 143657, 146682, 147845, 148238, 150856, 151307, 156387, 160656, 160718, 161084, 163949, 336, 718, 118105, 4521, 114, 582, 2152, 6624, 59429, 80748, 2998, 3055, 3116, 3855, 4131, 4201, 49013, 62331, 88932, 92210, 92954, 106873, 107314, 109742, 110873, 108, 131, 137, 183, 189, 244, 325, 447, 526, 561, 565, 571, 614, 621, 775, 831, 980, 1053, 1151, 1168, 1312, 1325, 1329, 1335, 1458, 1465, 1493, 1531, 1543, 1549, 1550, 1640, 1657, 1696, 1715, 1728, 1731, 1771, 1822, 1891, 1980, 1986, 1989, 1990, 2047, 2055, 2189, 2215, 2256, 2295, 2350, 2479, 2515, 2519, 2534, 2586, 2655, 2754, 2766, 2767, 2800, 2850, 2855, 2945, 2982, 2992, 3021, 3041, 3190, 3239, 3281, 3282, 3325, 3331, 3339, 3351, 3402, 3431, 3465, 3491, 3495, 3518, 3587, 3605, 3619, 3659, 3661, 3662, 3663, 3664, 3665, 3692, 3757, 3805, 3820, 3832, 3837, 3838, 3839, 3851, 3923, 3938, 3939, 3940, 3941, 3942, 3960, 3971, 5649, 8977, 34435, 132952, 148, 1555, 1928, 2400, 3025, 3487, 3602, 3870, 3985, 4189, 4319, 4324, 4337, 4401, 4411, 4610, 4804, 4854, 5039, 5057, 5063, 5079, 5167, 5227, 5230, 5231, 5232, 5233, 5234, 5301, 4445, 4453, 4981, 5182, 7355, 89388, 55250, 91104, 4101, 4541, 5041, 5042, 6966, 6991, 7192, 7307, 7738, 7892, 7951, 8138, 25995, 26005, 26012, 26317, 26413, 26702, 26886, 27441, 32395, 42946, 43832, 46772, 47810, 50005, 51709, 59935, 60760, 61026, 61210, 66427, 68486, 72224, 72630, 73488, 73741, 74438, 1311, 2191, 3883, 4753, 5117, 5278, 5413, 5864, 7204, 7312, 32153, 46574, 54768, 61465, 6771, 27724, 27871, 32666, 36931, 51927, 59016, 74450, 3349, 2342, 2708, 3976, 4173, 6035, 6056, 6073, 6828, 7208, 7299, 8121, 8143, 8591, 8779, 8954, 25852, 26663, 27768, 32591, 38384, 47728, 2284, 1671, 4640, 7352, 8070, 8713, 27876, 33124, 2661, 2923, 5223, 5466, 5503, 5516, 5517, 5535, 5575, 3454, 6332, 7453, 8642, 33296, 47122, 54734, 55100, 59985, 61250, 70898, 77414, 79588, 80858, 80860, 82152, 82499, 86817, 88179, 95567, 111913, 764, 1044, 2032, 3460, 3890, 4001, 27664, 73860, 757, 865, 1901, 2832, 617, 1164, 1450, 1539, 1563, 1571, 1819, 2008, 2063, 2869, 3003, 3047, 3303, 3338, 4026, 4076, 4208, 4399, 4538, 4591, 4592, 4605, 4796, 4930, 4984, 5224, 5236, 5352, 5395, 5427, 6531, 98000, 108514, 149606, 162542, 162672, 2849, 4469, 92008, 95761, 104881, 105954, 111931, 54780, 72294, 78174, 84637, 4104, 6039, 7340, 100553, 27544, 2887, 3031, 3276, 3596, 3933, 4051, 4053, 4156, 4198, 4233, 4268, 4397, 4471, 4477, 4602, 4634, 4812, 5356, 5573, 5582, 5636, 5779, 6143, 6302, 6348, 6349, 6427, 6514, 6798, 6812, 6814, 6862, 7016, 7245, 7258, 7319, 7372, 7895, 8136, 8290, 8447, 8743, 26409, 26464, 26750, 31000, 32291, 43558, 49688, 50064, 50792, 52730, 55294, 61289, 66785, 67361, 69118, 70545, 70984, 71823, 72694, 73386, 75803, 75816, 77191, 79259, 79590, 79946, 80590, 81949, 82093, 83177, 84696, 84950, 85399, 86028, 86593, 87444, 87483, 87785, 89305, 89427, 90343, 90522, 90738, 91126, 91128, 91273, 91323, 91325, 91470, 91688, 91873, 91935, 92048, 92198, 92439, 92665, 93242, 93563, 93980, 93982, 94011, 94323, 94494, 94672, 94919, 95067, 95201, 95508, 95744, 96114, 96530, 96726, 97328, 97470, 97858, 97870, 98160, 98175, 98230, 98279, 98585, 98836, 98908, 99005, 99106, 99415, 99574, 99846, 99992, 100226, 100304, 100326, 100390, 101283, 101360, 101415, 101529, 101884, 102165, 102278, 102378, 103221, 103502, 103543, 103596, 103755, 103819, 103865, 104076, 104078, 104129, 104245, 104760, 104906, 105037, 105121, 105254, 105351, 106542, 106839, 106883, 107702, 107945, 108601, 108715, 108949, 109042, 109191, 109295, 109317, 109372, 109576, 109853, 110297, 110611, 110826, 111663, 111680, 112303, 112497, 112749, 113186, 113225, 113416, 113532, 114762, 114818, 114925, 115151, 116207, 116413, 116419, 116849, 116887, 116985, 117107, 117511, 117590, 118248, 118326, 118354, 118702, 118814, 119068, 119655, 120635, 120783, 122490, 122932, 123947, 124859, 125916, 126420, 127096, 127194, 127204, 127319, 128592, 129250, 129657, 129659, 129737, 130083, 130450, 131714, 132333, 132462, 132488, 132618, 133281, 133365, 133377, 133545, 133782, 133798, 134158, 134859, 135536, 136305, 136654, 136666, 136800, 136816, 138546, 139415, 139642, 139915, 140237, 140725, 141422, 142536, 143255, 143257, 143410, 143472, 144714, 145150, 146688, 149590, 149612, 150401, 157407, 160440, 161830, 161918, 69529, 26462, 638, 245, 4741, 5818, 5913, 6022, 6091, 6679, 6690, 6884, 7011, 7990, 8273, 8577, 26947, 27416, 27700, 27875, 33750, 41912, 48032, 48593, 48856, 49265, 57845, 58029, 61646, 65259, 71640, 73101, 77810, 81819, 92004, 93693, 98913, 99675, 102995, 128616, 140152, 155611, 3453, 3575, 4342, 4724, 5229, 5264, 5271, 6033, 6295, 6342, 6369, 6762, 6769, 7260, 7625, 7627, 8256, 8453, 8699, 26791, 26843, 26854, 27826, 53138, 54251, 59549, 60086, 68835, 69495, 70762, 72947, 79163, 80584, 82608, 84414, 89870, 92613, 92966, 98933, 99609, 99615, 100017, 103731, 106417, 108551, 108795, 109183, 109359, 110058, 110781, 116855, 127728, 129009, 130522, 130628, 130960, 135264, 135266, 135268, 137403, 140739, 140741, 140743, 140745, 140747, 140749, 140751, 140753, 140755, 140757, 140759, 140761, 140763, 140880, 141124, 142068, 142240, 146443, 146501, 146604, 147037, 2103, 8504, 26819, 42009, 143859, 158314, 1692, 3845, 3909, 167, 563, 127124, 134246, 134528, 134783, 137595, 138204, 60832, 64997, 72380, 129, 4736, 6425]\n"
     ]
    }
   ],
   "source": [
    "print(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dictionary mapping ids (keys) to indexes (values)\n",
    "user_id_to_index = {x: i for i, x in enumerate(user_ids)}\n",
    "movie_id_to_index = {x: i for i, x in enumerate(movie_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a new column in the dataframe which contains the appropriate index for each user and movie\n",
    "df[\"user_index\"] = [user_id_to_index[i] for i in df[\"userId\"]]\n",
    "df[\"movie_index\"] = [movie_id_to_index[i] for i in df[\"movieId\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_index</th>\n",
       "      <th>movie_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759187</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759148</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1260759125</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759131</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759135</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759203</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1953</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759191</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759139</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759194</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759198</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759108</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2455</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759113</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759200</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3671</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759117</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355493</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>835355681</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>835355604</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355552</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>835355586</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating   timestamp  user_index  movie_index\n",
       "0        1       31     2.5  1260759144           0            0\n",
       "1        1     1029     3.0  1260759179           0            1\n",
       "2        1     1061     3.0  1260759182           0            2\n",
       "3        1     1129     2.0  1260759185           0            3\n",
       "4        1     1172     4.0  1260759205           0            4\n",
       "5        1     1263     2.0  1260759151           0            5\n",
       "6        1     1287     2.0  1260759187           0            6\n",
       "7        1     1293     2.0  1260759148           0            7\n",
       "8        1     1339     3.5  1260759125           0            8\n",
       "9        1     1343     2.0  1260759131           0            9\n",
       "10       1     1371     2.5  1260759135           0           10\n",
       "11       1     1405     1.0  1260759203           0           11\n",
       "12       1     1953     4.0  1260759191           0           12\n",
       "13       1     2105     4.0  1260759139           0           13\n",
       "14       1     2150     3.0  1260759194           0           14\n",
       "15       1     2193     2.0  1260759198           0           15\n",
       "16       1     2294     2.0  1260759108           0           16\n",
       "17       1     2455     2.5  1260759113           0           17\n",
       "18       1     2968     1.0  1260759200           0           18\n",
       "19       1     3671     3.0  1260759117           0           19\n",
       "20       2       10     4.0   835355493           1           20\n",
       "21       2       17     5.0   835355681           1           21\n",
       "22       2       39     5.0   835355604           1           22\n",
       "23       2       47     4.0   835355552           1           23\n",
       "24       2       50     4.0   835355586           1           24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the ratings\n",
    "\n",
    "As is good when working with ``gradient descent``, it helps to have our values on a similar range, and for that to be between 0 and 1. We can use the ``MinMaxScaler`` from ``Scikit-Learn`` to scale our ratings to between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100004.000000\n",
       "mean          3.543608\n",
       "std           1.058064\n",
       "min           0.500000\n",
       "25%           3.000000\n",
       "50%           4.000000\n",
       "75%           4.000000\n",
       "max           5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rating\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "##Pick the range\\\n",
    "df[\"rating\"] = MinMaxScaler().fit_transform(df[\"rating\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100004.000000\n",
       "mean          0.676357\n",
       "std           0.235125\n",
       "min           0.000000\n",
       "25%           0.555556\n",
       "50%           0.777778\n",
       "75%           0.777778\n",
       "max           1.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rating\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set\n",
    "\n",
    "We are making a **predictive model** that will take a **user** and **movie** and return a **rating**. \n",
    "\n",
    "For our training, we will make a dataset using the information we already know. In this context, our input feautres (``x``) are the movie and user indexes, and the our output (``y``) is the rating. \n",
    "\n",
    "We make a train - test split of ``10%`` to validate our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Inputs\n",
    "x = df[[\"user_index\", \"movie_index\"]]\n",
    "#Outputs\n",
    "y = df[\"rating\"]\n",
    "#Get train-test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重点 Predicted Rating = Dot Product(user_vector, item_vector) + user_bias + item_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dot Product Recommender Model\n",
    "\n",
    "Lets remember the model we're trying to make. \n",
    "\n",
    "\n",
    "```\n",
    "Predicted Rating = Dot Product(user_vector, item_vector) + user_bias + item_bias\n",
    "```\n",
    "\n",
    "\n",
    "Our target is to find a vector for each movie and user so that their dot product (+ their biases) is an accurate prediction for the rating that user would make for that movie. \n",
    "\n",
    "Each of these vectors will be contained in a matrix, that we call an **embedding**\n",
    "\n",
    "\n",
    "### The Embedding Layer \n",
    "\n",
    "Again, you can think of an embedding layer as a **one-hot encoding** layer the size of your **vocabulary**, followed by a **fully connected layer** the size of your embedding. \n",
    "\n",
    "Luckily, ```PyTorch``` has a layer already we can use, all we have to say is \n",
    "\n",
    "1. How many items we have (vocabulary size)\n",
    "\n",
    "2. The size of the embedding \n",
    "\n",
    "You might use something between 10-300, and this is something you will have to tune\n",
    "\n",
    "### New Arguments for ``__init__``\n",
    "\n",
    "Again, we will override the ```__init__()``` function, but this time we will add in some extra arguments. We can use this to pass in \n",
    "\n",
    "1. Number of users \n",
    "\n",
    "2. Number of movies\n",
    "\n",
    "3. Size of Embedding\n",
    "\n",
    "These get passed in when we make the new object \n",
    "\n",
    "```\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "\n",
    "```\n",
    "\n",
    "### Saving Variables and ```self```\n",
    "\n",
    "Finally, the last **Object-oriented** concept we'll need allows us to save things within the object. These are sometimes called ``instance variables`` or ``fields``, but the main thing you need to know is **these are like the variables we use all the time to store objects and data**, apart from they belong to the object, and only work within this context \n",
    "\n",
    "We use the keyword ```self``` within the object to refer to itself. We can use this to make layers in the ```__init__()``` function, store them in the object, and then reuse and update them in the ```forward()``` function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On every forwards pass (see ``forward()`` below)\n",
    "\n",
    "1. We take a batch of ``users`` and ``movies``\n",
    "\n",
    "\n",
    "2. Run them through the normal embedding and bias embedding layers respectively \n",
    "\n",
    "\n",
    "3. Get the vectors for each out \n",
    "\n",
    "\n",
    "4. Get the dot product of the user and movie vectors \n",
    "\n",
    "\n",
    "5. Add the biases \n",
    "\n",
    "\n",
    "6. Run through a sigmoid\n",
    "\n",
    "\n",
    "7. Return!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderNet(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_size=20):\n",
    "        super().__init__()    #initialize\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, embedding_size) # Embed element num_users\n",
    "        self.user_bias = torch.nn.Embedding(num_users, 1)  # embedding_size)\n",
    "        self.movie_embedding = torch.nn.Embedding(num_movies, embedding_size)\n",
    "        self.movie_bias = torch.nn.Embedding(num_movies, 1)\n",
    "        self.sig = torch.nn.Sigmoid() \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #Split out indexes  \n",
    "        user_indexes = inputs[:, 0]\n",
    "        movie_indexes = inputs[:, 1]\n",
    "        #Forward pass on embedding layer \n",
    "        user_vector = self.user_embedding(user_indexes) \n",
    "        user_bias = self.user_bias(user_indexes).flatten()\n",
    "        movie_vector = self.movie_embedding(movie_indexes)\n",
    "        movie_bias = self.movie_bias(movie_indexes).flatten()\n",
    "        #Dot product\n",
    "        dot = (user_vector * movie_vector).sum(1)\n",
    "        with_bias = dot + user_bias + movie_bias\n",
    "        #Activation function\n",
    "        output = self.sig(with_bias)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick Embedding size\n",
    "EMBEDDING_SIZE = 16\n",
    "#Make new object (calls __init__())\n",
    "num_users = len(user_ids)\n",
    "num_movies = len(movie_ids)\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Datasets in PyTorch\n",
    "\n",
    "PyTorch requires a little bit of manual set up for the training loop that we got for free in ``Keras`` with the ``fit()`` function. \n",
    "\n",
    "Below we see two for loops, one that loops round every epoch (once through the entire dataset) and inside that that loops through each batch (a subset of a chosen size).\n",
    "\n",
    "``PyTorch`` gives us a ``DataLoader`` object which helps with the batching process.\n",
    "\n",
    "Within that inner loop we pass in part of the training set, calculate the loss and update the weights based on this. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MoviesDataset(Dataset): \n",
    "    def __init__(self, X,y):\n",
    "        self.X = torch.IntTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use our train - validation split to make DataLoader objects\n",
    "train_dl = DataLoader(MoviesDataset(x_train.values,y_train.values), batch_size=64, shuffle=True)\n",
    "validation_dl = DataLoader(MoviesDataset(x_val.values,y_val.values), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "#Use Mean Squared Error as a loss function\n",
    "loss_fn = torch.nn.MSELoss() \n",
    "#Use the Adam algorithm to update the weights based on the loss\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.1750703603029251 Validation Loss 0.12003464996814728\n",
      "Loss 0.078511081635952 Validation Loss 0.08712414652109146\n",
      "Loss 0.04915506765246391 Validation Loss 0.07325321435928345\n",
      "Loss 0.03734564408659935 Validation Loss 0.0670546367764473\n",
      "Loss 0.031535804271698 Validation Loss 0.06623506546020508\n",
      "Loss 0.027926793321967125 Validation Loss 0.06447163224220276\n",
      "Loss 0.025508688762784004 Validation Loss 0.06481712311506271\n",
      "Loss 0.02382367104291916 Validation Loss 0.06481997668743134\n",
      "Loss 0.022606132552027702 Validation Loss 0.0656891018152237\n",
      "Loss 0.021785156801342964 Validation Loss 0.06368888914585114\n"
     ]
    }
   ],
   "source": [
    "#Use a for loop to repeat for the desired number of epochs \n",
    "for i in range(epochs):\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    #Use a for loop for each batch (provided by the Dataloader)\n",
    "    running_loss = 0.0\n",
    "    for (index, batch) in enumerate(train_dl):\n",
    "        \n",
    "        #Get batch \n",
    "        inputs, labels = batch\n",
    "        model.zero_grad()\n",
    "        \n",
    "        #Forward pass\n",
    "        prediction = model(inputs)\n",
    "        \n",
    "        #Get Loss\n",
    "        loss = loss_fn(prediction, labels)\n",
    "        \n",
    "        #Update weights (back prop)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "    \n",
    "    avg_loss = running_loss / (index + 1)\n",
    "\n",
    "    model.train(False)\n",
    "\n",
    "    #Now try with the validation set (no need to update weights, just get loss)\n",
    "    running_vloss = 0.0\n",
    "    for index, vdata in enumerate(validation_dl):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (index + 1)\n",
    "    print('Loss {} Validation Loss {}'.format(avg_loss, avg_vloss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Reload models\n",
    "\n",
    "We can save the weights of our model (the important parts that we have learned) to file so we don't have to train again in future\n",
    "\n",
    "We can then load them into a new model from file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，通过调用torch.load()函数加载了预训练的模型参数。模型参数保存在名为'model_weights.pth'的文件中，load_state_dict()方法将这些参数加载到model实例中，使其具有预训练的权重。\n",
    "\n",
    "最后，通过调用model.eval()方法将模型设置为评估模式。在评估模式下，模型的行为可能会略有不同，例如在前向传播时可能不会应用一些正则化技术或随机性操作，而是以确定性的方式进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecommenderNet(\n",
       "  (user_embedding): Embedding(671, 16)\n",
       "  (user_bias): Embedding(671, 1)\n",
       "  (movie_embedding): Embedding(9066, 16)\n",
       "  (movie_bias): Embedding(9066, 1)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Embeddings \n",
    "\n",
    "We can access the **embedding layers** in our model object. This is the embedding and we can see is has a shape of ```num_users x EMBEDDING_SIZE```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 16, Embedding(671, 16))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users, EMBEDDING_SIZE, model.user_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions \n",
    "\n",
    "Now, we can use our trained model to make predictions, and with the predicted ratings, we can pick some recommendations!\n",
    "\n",
    "In order to get the ratings for all movies for a given user, we need to get pass in our data in the form \n",
    "\n",
    "```\n",
    "[\n",
    "    [user_index, movie_1_index],\n",
    "    [user_index, movie_2_index],\n",
    "    [user_index, movie_3_index],\n",
    "    .....\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieId', 'title', 'genres'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "movie_data = pd.read_csv(\"C:/Users/86158/Desktop/semester 3/Personalisation-22-23-main/data/ml-latest-small/movies.csv\")\n",
    "movie_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions and `argsort()`\n",
    "\n",
    "Once we have the predicted ratings for each film, we need to get the **Top N**\n",
    "\n",
    "Here we use `np.argsort()`, which does the sort based on the **ratings** but returns the **indexes** rather than the **ratings themselves**. We can then use this to look up the `movie_ids` and then the `title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(user, n=10): \n",
    "    #Get Movie Names\n",
    "    top_n_indexes = get_top_n_indexes(user, n)\n",
    "    top_n = get_names_for_indexes(top_n_indexes)\n",
    "    return top_n\n",
    "\n",
    "def get_names_for_indexes(indexes):\n",
    "    return [movie_data[movie_data[\"movieId\"]==movie_ids[i]][\"title\"].item() for i in indexes]\n",
    "\n",
    "def get_top_n_indexes(user, n = 10):\n",
    "    #For one user, make a pair with every movie index\n",
    "    x = torch.IntTensor([[user, i] for i in np.arange(num_movies)])\n",
    "    #Predict \n",
    "    predicted_ratings = model(x)\n",
    "    #Get Top-N indexes\n",
    "    top_n_indexes = predicted_ratings.argsort()[-n:]\n",
    "    return top_n_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cook the Thief His Wife & Her Lover, The (1989)',\n",
       " 'Stake Land (2010)',\n",
       " 'Leprechaun (1993)',\n",
       " 'Domino (2005)',\n",
       " 'Secret, The (2006)',\n",
       " 'Woman in the Window, The (1944)',\n",
       " 'Dr. Mabuse: The Gambler (Dr. Mabuse, der Spieler) (1922)',\n",
       " 'Lawless (2012)',\n",
       " 'Ernest Scared Stupid (1991)',\n",
       " 'Richard III (1995)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random users top 10\n",
    "get_top_n(np.random.randint(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'night Mother (1986)\",\n",
       " 'My Girl 2 (1994)',\n",
       " 'Chinoise, La (1967)',\n",
       " 'Sammy and Rosie Get Laid (1987)',\n",
       " 'Town & Country (2001)',\n",
       " 'Curse of the Jade Scorpion, The (2001)',\n",
       " 'Children of Paradise (Les enfants du paradis) (1945)',\n",
       " 'Elektra Luxx (2010)',\n",
       " 'Fawlty Towers (1975-1979)',\n",
       " 'Power of Nightmares, The: The Rise of the Politics of Fear (2004)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "Please remember to comment your code clearly, submit ``.ipynb`` \n",
    "\n",
    "## Task 1\n",
    "\n",
    "We're going to ask you take the trained model and write the code to make two metrics - **Diversity** and **Novelty**. You should end up with **one statistic** for each that tells you something about the recommendations of the trained model based on the **whole dataset**.\n",
    "\n",
    "\n",
    "#### Pro Tip\n",
    "\n",
    "This will take quite a long time to run on the whole dataset, so start off by trying to get the code to work for **one user**, then expand to **two users**, then **every user**.\n",
    "\n",
    "### Diversity \n",
    "\n",
    "This tells us what the mean diversity (inverse of the similarity, based on movie embeddings) between each film in every users Top 10 films is. \n",
    "\n",
    "1. Calculate every user's top 10\n",
    "\n",
    "\n",
    "2. For each top 10, get the embedding for each film then use this to calculate the similarity matrix\n",
    "\n",
    "\n",
    "3. Invert similarity to get the difference\n",
    "\n",
    "\n",
    "4. Get mean difference for each top 10 \n",
    "\n",
    "\n",
    "5. Report the mean for whole dataset (every top 10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def diversity(user, n=10):\n",
    "    # Calculate every user's top 10\n",
    "    top_n_indexes = get_top_n_indexes(user, n)\n",
    "\n",
    "    # For each top 10, get the embedding for each film then use this to calculate the similarity matrix\n",
    "    embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
    "\n",
    "    # Compute the similarity matrix\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    # Invert similarity to get the difference\n",
    "    diversity = 1 - similarity_matrix\n",
    "    \n",
    "    # Get mean difference for each top 10\n",
    "    mean_diversity = np.mean(diversity)\n",
    "\n",
    "    return mean_diversity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5931239, 0.6216045, 0.5891719, 0.5738561, 0.56538606, 0.5798974, 0.5778276, 0.635664, 0.5897581, 0.65690565, 0.5250489, 0.552624, 0.6247327, 0.605624, 0.65394104, 0.5045446, 0.76055074, 0.64374083, 0.7152416, 0.5562381, 0.68363875, 0.61900043, 0.7665795, 0.56989825, 0.5573562, 0.56450105, 0.5774123, 0.5176212, 0.47658643, 0.72866327, 0.63914657, 0.632309, 0.6068055, 0.63071233, 0.47236064, 0.5770765, 0.59509027, 0.6267693, 0.51847345, 0.6027948, 0.7799855, 0.6397724, 0.68513405, 0.60608065, 0.5417098, 0.55938166, 0.5431354, 0.8604151, 0.56843734, 0.66344696, 0.5799992, 0.5766608, 0.59598154, 0.5716858, 0.63210917, 0.57397664, 0.673184, 0.58721614, 0.59698695, 0.555599, 0.592847, 0.6239634, 0.59161144, 0.41680786, 0.50175244, 0.6219455, 0.60969424, 0.6337139, 0.63418823, 0.604798, 0.59649646, 0.74737066, 0.7665993, 0.5315231, 0.57481927, 0.6114902, 0.7592916, 0.60221887, 0.60824585, 0.58134866, 0.60833657, 0.6200317, 0.56753266, 0.7836663, 0.5682677, 0.4507242, 0.66694456, 0.5784786, 0.52576816, 0.50820976, 0.6175619, 0.5274521, 0.7611932, 0.5855459, 0.71105635, 0.5254733, 0.5764553, 0.5380388, 0.6968509, 0.6104986, 0.52301264, 0.68098795, 0.60081434, 0.67338157, 0.82560515, 0.5036333, 0.6471606, 0.5891475, 0.54316866, 0.5938445, 0.7014856, 0.4920128, 0.5120458, 0.5800404, 0.5727476, 0.54591006, 0.5197652, 0.48791355, 0.5523258, 0.5835132, 0.6070841, 0.6760518, 0.5653154, 0.536933, 0.4675618, 0.5431752, 0.49054977, 0.630842, 0.59766024, 0.79654884, 0.43958667, 0.54486245, 0.58042943, 0.54740334, 0.57762444, 0.5789551, 0.54605097, 0.5294777, 0.6320838, 0.5853242, 0.5417879, 0.61902964, 0.49007237, 0.5826102, 0.6291347, 0.61501837, 0.58057004, 0.5072025, 0.5940793, 0.65994453, 0.5972021, 0.64297944, 0.54306203, 0.584487, 0.5336531, 0.46995527, 0.7255979, 0.5879572, 0.581886, 0.55823606, 0.5872745, 0.6253819, 0.5746593, 0.65521455, 0.64761275, 0.6322113, 0.52346843, 0.60512984, 0.58967924, 0.5522744, 0.58150965, 0.5818114, 0.6424876, 0.5457266, 0.6331414, 0.6878992, 0.61852145, 0.62724096, 0.50764364, 0.6228171, 0.6144771, 0.6436865, 0.46896863, 0.5997402, 0.6396827, 0.5481512, 0.627896, 0.61768126, 0.54309267, 0.6256736, 0.5447116, 0.4933089, 0.63600737, 0.5450507, 0.6979157, 0.6173563, 0.5534002, 0.6175567, 0.8275729, 0.5388529, 0.58323646, 0.7116659, 0.50862336, 0.6617199, 0.62237084, 0.5580745, 0.54396117, 0.6261872, 0.54949594, 0.63567466, 0.5398965, 0.733135, 0.550897, 0.7003765, 0.48068827, 0.5754144, 0.6176034, 0.62144375, 0.54816383, 0.6792502, 0.5267265, 0.5662737, 0.5689445, 0.62198263, 0.5670531, 0.62366563, 0.60344565, 0.55601174, 0.56484884, 0.5484066, 0.5935896, 0.585582, 0.6523887, 0.48977837, 0.44757515, 0.56394106, 0.5538536, 0.6815095, 0.69461226, 0.65522486, 0.54729104, 0.65568835, 0.7359805, 0.5126255, 0.6548874, 0.5741586, 0.652459, 0.60633314, 0.50478286, 0.6038419, 0.7246914, 0.6146703, 0.68589544, 0.6470922, 0.643661, 0.6218281, 0.56471807, 0.5643867, 0.65963656, 0.63803816, 0.45071223, 0.5521413, 0.72540873, 0.45993423, 0.6440532, 0.6378925, 0.55963254, 0.6959782, 0.6042555, 0.8293959, 0.63511723, 0.6066696, 0.68144065, 0.6410238, 0.6446427, 0.4494832, 0.6442277, 0.5822006, 0.5407444, 0.6438139, 0.6834627, 0.5363667, 0.6106715, 0.5904429, 0.5946321, 0.4896071, 0.6865321, 0.5923626, 0.5643, 0.54080373, 0.5835349, 0.76056486, 0.5481575, 0.74024475, 0.67306405, 0.5544033, 0.59060043, 0.5797614, 0.5874598, 0.6047088, 0.55160695, 0.56784695, 0.6255875, 0.51915026, 0.5533064, 0.8260569, 0.705569, 0.60936284, 0.54331106, 0.47157478, 0.703201, 0.5747536, 0.6513227, 0.55916196, 0.4862881, 0.71552294, 0.5096341, 0.5628275, 0.6088555, 0.67575395, 0.47845092, 0.4875788, 0.56615156, 0.7523806, 0.44203937, 0.5357007, 0.5908995, 0.758625, 0.63069105, 0.5058421, 0.549342, 0.40641215, 0.5248921, 0.57381356, 0.6342979, 0.51368165, 0.6355769, 0.62297004, 0.7109644, 0.6409166, 0.58798057, 0.6445165, 0.5962863, 0.63582784, 0.58194315, 0.5221033, 0.6195695, 0.59275746, 0.5201037, 0.55476123, 0.47830757, 0.5966995, 0.78093505, 0.5853001, 0.8169738, 0.5511824, 0.6001233, 0.6773012, 0.59983593, 0.70904523, 0.51161325, 0.703456, 0.61842847, 0.5472311, 0.6302232, 0.5427685, 0.54396397, 0.5375763, 0.6648857, 0.5947067, 0.6375738, 0.5777805, 0.69591814, 0.5617233, 0.5297705, 0.65674424, 0.51691294, 0.5832642, 0.5713154, 0.8059823, 0.63252366, 0.5240617, 0.608187, 0.76085013, 0.63117945, 0.7001071, 0.5699048, 0.62079847, 0.6308743, 0.56978273, 0.5685656, 0.5982119, 0.59099406, 0.5652643, 0.5011828, 0.6851292, 0.70984656, 0.63062406, 0.5058022, 0.6155671, 0.58960736, 0.7379689, 0.54507196, 0.5973747, 0.5490359, 0.53736067, 0.769924, 0.5852122, 0.6174194, 0.5886046, 0.57937944, 0.53604746, 0.5535795, 0.5171175, 0.5548545, 0.60225856, 0.53883106, 0.610739, 0.63135207, 0.46353617, 0.6440857, 0.5924255, 0.6562952, 0.5731986, 0.6241267, 0.6535516, 0.71452665, 0.571121, 0.589124, 0.59551656, 0.6150066, 0.5242145, 0.607552, 0.57537913, 0.59294504, 0.54196185, 0.600018, 0.5523737, 0.63817286, 0.51434726, 0.6142834, 0.7260974, 0.5079124, 0.5590479, 0.5665455, 0.52640814, 0.58061117, 0.56489396, 0.5935822, 0.49978983, 0.5203306, 0.7530167, 0.5257039, 0.48738346, 0.55350405, 0.5767951, 0.73312056, 0.65162224, 0.5140679, 0.49239442, 0.7053647, 0.55586016, 0.6961105, 0.5797215, 0.4991449, 0.6374318, 0.54237163, 0.84930915, 0.5347048, 0.5565922, 0.83572614, 0.64854723, 0.5520313, 0.56660575, 0.76306254, 0.5391787, 0.5387468, 0.61229134, 0.6433139, 0.6197636, 0.62991667, 0.581492, 0.60810775, 0.57161796, 0.5198191, 0.620505, 0.66653585, 0.58530295, 0.5587978, 0.5426431, 0.5835535, 0.58406425, 0.492969, 0.6455501, 0.55940425, 0.56071424, 0.6233035, 0.52820307, 0.46824732, 0.48998693, 0.702413, 0.6141584, 0.63624686, 0.48535794, 0.8876361, 0.47243556, 0.5279599, 0.4987605, 0.7203629, 0.67769086, 0.4509679, 0.58790714, 0.5986424, 0.71652627, 0.6054514, 0.71381736, 0.59786206, 0.712756, 0.6314386, 0.66677207, 0.6384357, 0.7904732, 0.61012614, 0.4982887, 0.6096187, 0.5708552, 0.57614744, 0.5840877, 0.67435557, 0.5655672, 0.6233586, 0.6683857, 0.6475785, 0.7591354, 0.5577467, 0.62135696, 0.55512, 0.57956856, 0.56302667, 0.57279086, 0.6612195, 0.56245786, 0.55814385, 0.7195074, 0.5640561, 0.51190954, 0.45241252, 0.6119864, 0.5916547, 0.70002234, 0.5634405, 0.63876575, 0.679476, 0.63377047, 0.570067, 0.4873952, 0.6183689, 0.7063954, 0.53836036, 0.7911861, 0.71034086, 0.6670115, 0.6972646, 0.66185373, 0.6270884, 0.613111, 0.5848388, 0.53137445, 0.65237844, 0.5041392, 0.57323354, 0.7770435, 0.57469714, 0.6913125, 0.60197425, 0.5385544, 0.6646519, 0.57581675, 0.6142094, 0.824306, 0.58334434, 0.6456922, 0.5710682, 0.67534643, 0.73399377, 0.4794946, 0.71967745, 0.5956029, 0.69940984, 0.6484549, 0.5719, 0.59927046, 0.6006489, 0.48182517, 0.5631148, 0.602604, 0.6867032, 0.7857216, 0.64641017, 0.5357906, 0.44342026, 0.5947466, 0.58973956, 0.59896713, 0.7199697, 0.6531178, 0.77535653, 0.74162966, 0.52693826, 0.6349361, 0.5379932, 0.593964, 0.5567333, 0.5190656, 0.69820476, 0.5729026, 0.5311683, 0.62362623, 0.65066034, 0.55089813, 0.58175474, 0.5950611, 0.5033578, 0.77508646, 0.59372884, 0.680603, 0.6743214, 0.59977007, 0.5696542, 0.49487793, 0.6201205, 0.4734195, 0.58314455, 0.59697, 0.5762283, 0.6816089, 0.6007252, 0.5653585, 0.6059574, 0.6051789, 0.7087939, 0.58537126, 0.57238114, 0.62146044, 0.57733065, 0.59019685, 0.53658956, 0.6847695, 0.704844, 0.5817575, 0.543989, 0.599522, 0.56568205, 0.7557253, 0.5404687, 0.5426467, 0.6324972, 0.5042394, 0.6778177, 0.5000832, 0.5990504, 0.6562971, 0.5738285, 0.85567796, 0.6268524, 0.5757681, 0.6022583, 0.50491303, 0.66693616, 0.5874964, 0.69363356]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n",
      "C:\\Users\\86158\\AppData\\Local\\Temp\\ipykernel_4992\\2900608899.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = model.movie_embedding(torch.tensor(top_n_indexes)).detach().numpy()\n"
     ]
    }
   ],
   "source": [
    "# Compute the diversity for each user\n",
    "diversities = [diversity(user) for user in range(num_users)]\n",
    "print(diversities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Diversity:  0.6026617\n"
     ]
    }
   ],
   "source": [
    "# Report the mean diversity for the whole dataset\n",
    "mean_diversity = np.mean(diversities)\n",
    "print(\"Mean Diversity: \", mean_diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty \n",
    "\n",
    "This tells us what the mean popularity (e.g. mean rating) of the films in every users Top 10 films is \n",
    "\n",
    "1. Calculate every user's top 10\n",
    "\n",
    "\n",
    "2. For each top 10, get the mean rating for each film (based on the original **MovieLens Small** dataset (``df = pd.read_csv(\"ml-latest-small/ratings.csv\")``). \n",
    "\n",
    "\n",
    "3. Get the mean rating for each top 10.\n",
    "\n",
    "\n",
    "4. Report the mean for the whole dataset (every top 10).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novelties:  [0.7037037037037036, 0.7388888888888888, 0.7866666666666667, 0.6348148148148147, 0.5940503432494278, 0.569927536231884, 0.8833333333333332, 0.8486111111111111, 0.77010582010582, 0.8333333333333334, 0.8185185185185183, 0.6777777777777777, 0.8657608695652174, 0.7087301587301587, 0.9777777777777779, 0.8269841269841269, 0.8444444444444443, 0.9407407407407407, 0.9222222222222222, 0.7283475783475784, 0.908974358974359, 0.6801587301587302, 0.8171497584541061, 0.7833333333333334, 0.8080515297906603, 0.7298148148148148, 0.6671497584541063, 0.6312678062678062, 0.7638888888888887, 0.794927536231884, 0.8209876543209876, 0.85, 0.7834188034188033, 0.9888888888888889, 0.728114478114478, 0.837037037037037, 0.8055555555555556, 0.8060386473429952, 0.6747008547008546, 0.5710144927536231, 0.8722222222222221, 0.7144444444444444, 0.904830917874396, 0.6334259259259258, 0.8849206349206348, 0.6075224292615597, 0.5966931216931217, 0.9060386473429952, 0.7529790660225443, 0.7752979066022544, 0.8142857142857143, 0.7986312399355877, 0.7222222222222221, 0.7944444444444445, 0.8847222222222222, 0.883816425120773, 0.8535714285714286, 0.7694444444444445, 0.5874999999999999, 0.85, 0.7833333333333333, 0.9944444444444445, 0.6555555555555556, 0.5605820105820106, 0.8111111111111111, 0.8545454545454545, 0.7783333333333332, 0.8238624338624337, 0.6364550264550265, 0.8277777777777778, 0.6406878306878306, 0.8893719806763285, 0.9592592592592591, 0.7648148148148148, 0.5887861066808434, 0.9222222222222222, 0.9190016103059581, 0.7555555555555555, 0.9070370370370371, 0.5592592592592591, 0.882716049382716, 0.7555555555555555, 0.6103703703703702, 0.857890499194847, 0.8579365079365079, 0.8731481481481481, 0.8962962962962961, 0.9574074074074075, 0.38571428571428573, 0.7730158730158729, 0.8814814814814815, 0.8903703703703705, 0.9486312399355878, 0.9685185185185186, 0.8555555555555555, 0.9444444444444444, 0.8603174603174603, 0.7944444444444445, 0.9055555555555556, 0.9, 0.7260846560846559, 0.888888888888889, 0.9570370370370369, 0.8722222222222223, 0.8930756843800323, 0.7194041867954912, 0.8492521367521366, 0.6888888888888889, 0.746025641025641, 0.736111111111111, 0.8115942028985508, 0.7133333333333334, 0.7333333333333334, 0.5772558922558921, 0.7087301587301587, 0.7199782135076253, 0.8333333333333333, 0.8328042328042328, 1.0, 0.687037037037037, 0.8538461538461538, 0.6782608695652174, 0.6675925925925925, 0.6885185185185184, 0.9633333333333333, 0.6917378917378917, 0.8792592592592593, 0.9233333333333335, 0.888137412775094, 0.9393719806763284, 0.9666666666666666, 0.8022222222222222, 0.8291887125220458, 0.8118518518518518, 0.6808856682769726, 0.9348148148148148, 0.474927536231884, 0.773723358908781, 0.6694444444444444, 0.8642857142857142, 0.7477777777777777, 0.7876811594202898, 0.6180555555555556, 0.8177777777777777, 0.5796296296296296, 0.8299999999999998, 0.5611111111111111, 0.9388888888888889, 0.9425925925925925, 0.7967793880837359, 0.6582608695652173, 0.827849002849003, 0.8642857142857142, 0.6587301587301587, 0.8299823633156966, 0.5546296296296296, 0.8703703703703702, 0.835024154589372, 0.9336700336700335, 0.8277777777777777, 0.6212238325281804, 0.8467264780308259, 0.9314814814814815, 0.7153945249597423, 0.9166666666666666, 0.7962962962962963, 0.7388888888888888, 0.9407925407925408, 0.6659259259259258, 0.861111111111111, 0.961111111111111, 0.6958994708994709, 0.8717793880837359, 0.7404558404558405, 0.7053609916653395, 0.9055555555555556, 0.72311939268461, 0.8004830917874395, 0.6787037037037036, 0.5574495820872633, 0.7067632850241545, 0.8776435856146001, 0.8462962962962962, 0.7515700483091787, 0.8666666666666666, 0.6143156199677938, 0.871345029239766, 0.9555555555555555, 0.794990484555702, 0.7675627240143369, 0.8628019323671496, 0.7703703703703704, 0.737037037037037, 0.8351851851851851, 0.9444444444444444, 0.7059700176366842, 0.5505291005291004, 0.7351851851851852, 0.9338164251207729, 0.7925550435227855, 0.887962962962963, 0.7652979066022544, 0.8197849462365591, 0.8222222222222222, 0.687037037037037, 0.8800000000000001, 0.8270833333333332, 0.6972222222222222, 0.95, 0.7203661327231121, 0.9244444444444444, 0.8930756843800323, 0.7811447811447811, 0.8811965811965813, 0.9555555555555555, 0.8449597423510466, 0.6685185185185185, 0.7518181818181817, 0.8055555555555556, 0.7620531400966184, 0.8292592592592593, 0.8229629629629629, 0.925, 0.7690291005291006, 0.5833333333333333, 0.6152979066022544, 0.786038647342995, 0.6388888888888888, 0.6722222222222222, 0.7516908212560386, 0.746031746031746, 0.7940740740740739, 0.8004830917874395, 0.9322222222222223, 0.8425396825396826, 0.8981481481481481, 0.6046296296296296, 0.8555555555555555, 0.8782608695652174, 0.9944444444444445, 0.7027777777777777, 0.9648148148148149, 0.8592592592592592, 0.7611111111111111, 0.7777777777777778, 0.8722222222222221, 0.837037037037037, 0.8222222222222222, 0.762962962962963, 0.893068783068783, 0.8777777777777779, 0.6828571428571428, 0.9, 0.8944444444444445, 0.7393827160493828, 0.5611111111111111, 0.608994708994709, 0.8033333333333333, 0.5888888888888888, 0.7577777777777778, 0.8997306397306396, 0.9666666666666666, 0.9041867954911433, 0.9055555555555556, 0.9185185185185185, 0.922866344605475, 0.9277777777777778, 0.9368686868686869, 0.9034567901234567, 0.888888888888889, 0.6334989648033126, 0.7111772486772487, 0.8779541446208114, 0.7499999999999998, 0.8215942028985506, 0.825925925925926, 0.7094778007821485, 0.8349033816425122, 0.8456790123456791, 0.8407407407407408, 0.8303976217019695, 0.837037037037037, 0.7814814814814813, 0.8888888888888887, 0.8755555555555554, 0.9666666666666666, 0.8932367149758453, 0.5060386473429952, 0.8074074074074072, 0.8155555555555555, 0.8341666666666667, 0.7727053140096618, 0.8640211640211639, 0.8615942028985508, 0.8870370370370371, 0.5244444444444445, 0.8777777777777779, 0.5764021164021165, 0.9740740740740741, 0.8284219001610305, 0.8240740740740741, 0.5848084886128364, 0.8555555555555555, 0.5712037037037037, 0.8037037037037038, 0.8937198067632851, 0.8415942028985507, 0.5750862663906141, 0.8671296296296296, 0.7739080112721417, 0.9671497584541063, 0.9311640211640212, 0.8, 0.8041269841269841, 0.37905982905982905, 0.8827053140096618, 0.7916666666666667, 0.9277777777777778, 0.7405228758169935, 0.9146464646464645, 0.8907407407407408, 0.804040404040404, 0.6703703703703703, 0.7162238325281803, 0.5925925925925926, 0.7313204508856683, 0.8164814814814815, 0.8375201288244767, 0.7928571428571428, 0.8092592592592591, 0.7055555555555555, 0.9, 0.4723370927318295, 0.8194444444444444, 0.8981481481481481, 0.5944444444444444, 0.7055555555555555, 0.8841867954911432, 0.6918411164787976, 0.7851851851851851, 0.837037037037037, 0.8784188034188034, 0.6531947319990798, 0.8233494363929147, 0.9027137736815156, 0.5592592592592592, 0.9296296296296296, 0.7822222222222222, 0.6656613756613756, 0.8707407407407407, 0.4833333333333333, 0.912962962962963, 0.825925925925926, 0.8444444444444444, 0.8555555555555555, 0.7592592592592592, 0.8171497584541061, 0.7575396825396825, 0.8, 0.8481481481481481, 0.548148148148148, 0.75, 0.5945868945868946, 0.2904761904761905, 0.5041666666666667, 0.6785233285233285, 0.9944444444444445, 0.8638271604938271, 0.663975155279503, 0.6542989417989419, 0.7055555555555555, 0.5504830917874395, 0.9222222222222222, 0.7474074074074074, 0.45185185185185184, 0.843827160493827, 0.7515873015873016, 0.8277777777777777, 0.661038647342995, 0.893075684380032, 0.7895061728395062, 0.6913662826706305, 0.9227053140096618, 0.856682769726248, 0.95, 0.8892592592592592, 0.9722222222222221, 0.9777777777777779, 0.825925925925926, 0.7577777777777778, 0.8425925925925926, 0.6782608695652174, 0.7, 0.7033333333333333, 0.625925925925926, 0.881964573268921, 0.8555555555555555, 0.8597150997150997, 0.44937198067632844, 0.912037037037037, 0.5888888888888889, 0.861111111111111, 0.8288888888888888, 0.7264090177133655, 0.8398148148148149, 0.8703703703703705, 0.9024959742351047, 0.8296296296296296, 0.7388888888888887, 0.5854761904761905, 0.7351851851851852, 0.8852979066022545, 0.8995061728395062, 0.8851851851851851, 0.6814814814814814, 0.6163561076604556, 0.8396296296296295, 0.5996649029982363, 0.8537037037037036, 0.5361111111111112, 0.8430756843800322, 0.8083333333333332, 0.9537037037037036, 0.7858465608465609, 0.6857142857142857, 0.9117283950617285, 0.8507936507936508, 0.7702441077441078, 0.8988095238095237, 0.7222222222222221, 0.73, 0.9, 0.9592592592592591, 0.9, 0.7962962962962963, 0.7296632996632996, 0.7914814814814815, 0.6123456790123456, 0.7286404416839198, 0.7759259259259259, 0.8099033816425122, 0.7304830917874396, 0.7393518518518519, 0.7671497584541063, 0.7777777777777778, 0.868148148148148, 0.8594444444444445, 0.5735449735449735, 0.5611111111111111, 0.8744444444444444, 0.5310144927536231, 0.9611965811965811, 0.9425925925925925, 0.7018518518518517, 0.8194444444444444, 0.75, 0.9277777777777778, 0.8666666666666666, 0.7966560340244551, 0.7718936678614098, 0.8525925925925926, 0.6927053140096617, 0.9888888888888889, 0.733068783068783, 0.8903703703703701, 0.5603864734299517, 0.9425925925925925, 0.9782608695652174, 0.515161454360539, 0.7486312399355878, 0.7801127214170693, 0.8488888888888889, 0.8108080808080806, 0.8564197530864197, 0.8866666666666667, 0.9081481481481483, 0.6896296296296296, 0.8746031746031745, 0.7555555555555555, 0.8912037037037038, 0.95, 0.8377777777777778, 0.7941595441595442, 0.842962962962963, 0.8222222222222222, 0.6148148148148148, 0.8382608695652174, 0.6370370370370371, 0.722860791826309, 0.8916666666666666, 0.7409320309320309, 0.663395061728395, 0.5625396825396826, 0.9592592592592591, 0.7844444444444444, 0.8655555555555555, 0.7063848631239935, 0.4796296296296296, 0.5972637944066514, 0.7046058879392213, 0.9, 0.7592592592592593, 0.8565302144249513, 0.32999999999999996, 0.9171497584541063, 0.757037037037037, 0.562037037037037, 0.837037037037037, 1.0, 0.768888888888889, 0.9888888888888889, 0.7321497584541062, 0.6472222222222221, 0.9625097125097124, 0.7208994708994709, 0.8537037037037036, 0.6356682769726247, 0.8925925925925926, 0.7741228070175439, 1.0, 0.9037037037037037, 0.8777777777777777, 0.8097423510466989, 0.6967132505175984, 0.8355218855218854, 0.6453864734299517, 0.9111111111111111, 0.9388888888888889, 0.9444444444444444, 0.8203703703703702, 0.8046913580246914, 0.8587749287749288, 0.9425925925925925, 0.8504830917874395, 0.5888888888888889, 0.7461111111111111, 0.7925925925925925, 0.4531746031746032, 0.8722222222222221, 0.7722222222222221, 0.8685185185185185, 0.6632102599493904, 0.7152979066022543, 0.8222222222222222, 0.680132275132275, 0.5784391534391534, 1.0, 0.7814814814814814, 0.7722222222222223, 0.9139090177133655, 0.7694444444444445, 0.9444444444444444, 0.8067793880837358, 0.7944444444444445, 0.8166666666666667, 0.6233238366571701, 0.8685185185185185, 0.924074074074074, 0.830952380952381, 0.9333333333333332, 0.7523349436392914, 0.7982608695652174, 0.8388888888888889, 0.9325925925925926, 0.448941798941799, 0.7120370370370369, 0.6972222222222222, 0.710830140485313, 0.8592592592592592, 0.7514153439153438, 0.6221001221001221, 0.8504830917874395, 0.8333333333333333, 0.9592592592592591, 0.788888888888889, 0.5989858906525574, 0.9244444444444444, 0.8851851851851851, 0.8765432098765432, 0.7930756843800323, 0.7435185185185185, 0.8321256038647343, 0.8, 0.8171497584541063, 1.0, 0.5148148148148148, 0.956038647342995, 0.9388888888888889, 0.7326086956521739, 0.9666666666666666, 0.874074074074074, 0.6088888888888888, 0.444973544973545, 0.6972222222222222, 0.6843079922027291, 0.9555555555555555, 0.7409151905528717, 0.9439814814814815, 0.8192592592592591, 0.6912962962962963, 0.9444444444444444, 0.6107142857142855, 0.8622383252818036, 0.6285493827160493, 0.7004830917874395, 0.9388888888888889, 0.9430756843800323, 0.9338164251207729, 0.599074074074074, 0.8080515297906601, 0.7388888888888888, 0.9018518518518519, 0.8317738791423002, 0.8783751493428913, 0.8814814814814815, 0.7537037037037038, 0.8234006734006734, 0.8434920634920635, 0.8722222222222221, 0.8181481481481481, 0.7179100529100528, 0.5676767676767678, 0.6058534621578099, 0.9004830917874397, 0.8730837789661319, 0.7759259259259259, 0.7503703703703704, 0.7839506172839507, 0.7057671957671958, 0.8317592592592593, 0.7777777777777778, 0.9833333333333332, 0.9380952380952381, 0.860648148148148, 0.5600529100529101, 0.8004830917874395, 0.8093827160493827, 0.728114478114478, 0.798148148148148, 0.5820703933747412, 0.8305555555555555, 0.7638003220611916, 0.7425925925925926, 0.7988888888888889, 0.9061728395061728, 0.6851851851851851, 0.706127946127946, 0.8041867954911434, 0.7474603174603175, 0.7839847752891231, 0.7055555555555555, 0.8930756843800323, 0.7922423510466988, 0.8560386473429953, 0.3015873015873015, 0.812962962962963, 0.7559527643585614, 0.9348148148148148, 0.8777777777777779, 0.7804040404040404, 0.8557407407407407, 0.9555555555555555, 0.5444444444444445, 0.9365942028985508, 0.8423349436392915, 0.5028265107212475, 0.8555555555555555, 0.5269576719576718, 0.7533931446974925, 0.36005291005291007, 0.744927536231884]\n",
      "Mean Novelty:  0.7874302730632259\n"
     ]
    }
   ],
   "source": [
    "def novelty(user, n=10):\n",
    "    # Calculate every user's top 10\n",
    "    top_n_indexes = get_top_n_indexes(user, n)\n",
    "\n",
    "    # Get the original movie IDs for the top n movies\n",
    "    top_n_movie_ids = [movie_ids[i] for i in top_n_indexes]\n",
    "\n",
    "    # For each top 10, get the mean rating for each film\n",
    "    mean_ratings = [df[df['movieId'] == movie_id]['rating'].mean() for movie_id in top_n_movie_ids]\n",
    "\n",
    "    # Compute the mean of the mean ratings\n",
    "    mean_novelty = np.mean(mean_ratings)\n",
    "\n",
    "    return mean_novelty\n",
    "\n",
    "# Get the mean rating for each top 10.\n",
    "novelties = [novelty(user) for user in range(num_users)]\n",
    "print(\"Novelties: \", novelties)\n",
    "# Report the mean for the whole dataset (every top 10).\n",
    "mean_novelty = np.mean(novelties)\n",
    "print(\"Mean Novelty: \", mean_novelty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## Task 2\n",
    "\n",
    "Using a dimensionality reduction approach (PCA? TSNE?), plot the top 30 best rated films on a 2-D graph based on their movie embeddings. Label each point with the title.\n",
    "\n",
    "There is infact ~400 films that have an average rating of 5 (because some films have only 1 rating). Can you adjust or filter for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Minimum number of ratings for a movie\n",
    "min_ratings = 5\n",
    "\n",
    "# Compute mean ratings and count ratings for each movie\n",
    "mean_ratings = df.groupby('movieId')['rating'].mean()\n",
    "count_ratings = df.groupby('movieId')['rating'].count()\n",
    "\n",
    "# Filter movies that have at least 5\n",
    "filtered_movies = mean_ratings[count_ratings >= min_ratings].sort_values(ascending=False)\n",
    "\n",
    "# Get the top 30 movies\n",
    "top_30_movies = filtered_movies.head(30).index.tolist()\n",
    "\n",
    "# Get the embeddings of the top 30 movies\n",
    "top_30_embeddings = model.movie_embedding(torch.tensor([movie_ids.index(movie_id) for movie_id in top_30_movies])).detach().numpy()\n",
    "\n",
    "# Reduce dimensionality using PCA\n",
    "pca = PCA(n_components=2)\n",
    "top_30_embeddings_pca = pca.fit_transform(top_30_embeddings)\n",
    "\n",
    "# Plot \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(top_30_embeddings_pca[:, 0], top_30_embeddings_pca[:, 1])\n",
    "\n",
    "for i, movie_id in enumerate(top_30_movies):\n",
    "    plt.annotate(movie_data[movie_data[\"movieId\"]==movie_id][\"title\"].item(),\n",
    "                 (top_30_embeddings_pca[i, 0], top_30_embeddings_pca[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
